# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

KitREC (Knowledge-Instruction Transfer for Recommendation) is a cross-domain recommendation research project. This directory (`Experimental_test/`) is the **evaluation workspace** for running model inference and computing metrics on test datasets.

**ì´ í´ë”ì˜ ì—­í• :**
- í•™ìŠµëœ ëª¨ë¸(HuggingFace Hub)ì„ ë¡œë“œí•˜ì—¬ Test Set í‰ê°€ ìˆ˜í–‰
- Hit@K, MRR, NDCG ë“± ì¶”ì²œ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
- User Typeë³„ stratified ë¶„ì„ ë° Baseline ë¹„êµ ì‹¤í—˜
- vLLM ê¸°ë°˜ ì¶”ë¡  í™˜ê²½ (Nvidia 5090, 36GB VRAM)

**Core Research Focus:**
- Cross-domain recommendation: Books (source) â†’ Movies/Music (target)
- Cold-start problem mitigation using LLM-based knowledge transfer
- 4 fine-tuned models: DualFT-Movies, DualFT-Music, SingleFT-Movies, SingleFT-Music

---

## Evaluation Metrics

### ì¶”ì²œ ì•„ì´í…œ ì„±ëŠ¥ í‰ê°€ (Ranking Metrics)

| Metric | ì„¤ëª… | ë²”ìœ„ |
|--------|------|------|
| **Hit@1** | ì •í™•íˆ 1ìœ„ë¡œ ì˜ˆì¸¡ | 0~100% |
| **Hit@5** | Top-5 ì•ˆì— ì •ë‹µ í¬í•¨ | 0~100% |
| **Hit@10** | Top-10 ì•ˆì— ì •ë‹µ í¬í•¨ (ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0) | 0~100% |
| **MRR** | Mean Reciprocal Rank (1ìœ„=1.0, 2ìœ„=0.5, 3ìœ„=0.33, 10ìœ„=0.1) | 0~1 |
| **NDCG@5** | Top-5 ë­í‚¹ í’ˆì§ˆ (DCG/IDCG) | 0~1 |
| **NDCG@10** | Top-10 ë­í‚¹ í’ˆì§ˆ (ë…¼ë¬¸ í‘œì¤€, 1ìœ„=1.0, 2ìœ„=0.631, 10ìœ„=0.289) | 0~1 |

### ì¶”ì²œ ì„¤ëª…ë ¥ í‰ê°€ (Explainability Metrics)

| Metric | ëŒ€ìƒ | ì„¤ëª… |
|--------|------|------|
| **MAE, RMSE** | `confidence_score` | ì˜ˆì¸¡ ì‹ ë¢°ë„ì™€ ì‹¤ì œ Rating ë¹„êµ |
| **Perplexity (PPL)** | `rationale` | ì¶”ì²œ ì„¤ëª…ì˜ ì–¸ì–´ì  í’ˆì§ˆ í‰ê°€ |

**âš ï¸ Perplexity ê³„ì‚° ë²”ìœ„:**
- **rationale í•„ë“œë§Œ** ê³„ì‚° (prompt, `<think>` ë¸”ë¡ ì œì™¸)
- Fine-tuned ëª¨ë¸ë¡œ PPL ì¸¡ì • (ëª¨ë¸ì˜ ìê¸° ìƒì„± í™•ì‹ ë„)
- ë‚®ì„ìˆ˜ë¡ í’ˆì§ˆ ì¢‹ìŒ (ëª¨ë¸ì´ í™•ì‹ ì„ ê°€ì§€ê³  ìƒì„±)

**âš ï¸ Confidence Score ì •ê·œí™” í•„ìˆ˜:**
- Test ë°ì´í„°: Rating 5ì  ë§Œì  (1~5)
- Model ì¶œë ¥: confidence_score **1~10** float (Template ëª…ì‹œ)
- í‰ê°€ ì‹œ ìŠ¤ì¼€ì¼ ì •ê·œí™” í•„ìš”: `normalized = confidence / 2`
- âš ï¸ confidence_score = 0 ì€ íŒŒì‹± ì˜¤ë¥˜ë¡œ ì²˜ë¦¬

---

## User Type & Core Level í‰ê°€

### Core Level ê¸°ì¤€ (Target Domain ìƒí˜¸ì‘ìš© ìˆ˜)

| Target Core | User Type | Count/Domain | ì„¤ëª… | Training Model |
|-------------|-----------|--------------|------|----------------|
| **1-core** | source_only | 3,000 | ê·¹í•œ Cold-start (target=1) | SingleFT |
| **2-core** | cold_start_2core | 3,000 | ì‹¬ê°í•œ Cold-start (target=2) | DualFT |
| **3-core** | cold_start_3core | 3,000 | ì¤‘ê°„ Cold-start (target=3) | DualFT |
| **4-core** | cold_start_4core | 3,000 | ê²½ë¯¸í•œ Cold-start (target=4) | DualFT |
| **5-core** | overlapping (target 5~9) | í•„í„°ë§ í•„ìš” | Warm ì‹œì‘ | DualFT |
| **10-core** | overlapping (targetâ‰¥10) | í•„í„°ë§ í•„ìš” | í’ë¶€í•œ Target | DualFT |

### Model-User Type ë§¤í•‘

| Model | User Types | Samples | íŠ¹ì§• |
|-------|------------|---------|------|
| **DualFT-Movies** | overlapping + cold_start_2/3/4core | 12,000 | Books+Movies ì´ë ¥ í™œìš© |
| **DualFT-Music** | overlapping + cold_start_2/3/4core | 12,000 | Books+Music ì´ë ¥ í™œìš© |
| **SingleFT-Movies** | source_only_movies | 3,000 | Books ì´ë ¥ë§Œ (ê·¹í•œ Cold-start) |
| **SingleFT-Music** | source_only_music | 3,000 | Books ì´ë ¥ë§Œ (ê·¹í•œ Cold-start) |

---
## User Typeë³„ íŒŒì¸íŠœë‹ ëª¨ë¸ ë§¤í•‘ í…Œì´ë¸”

### 1. User Type Definition & Model Assignment Table
| User Type | Condition | Target Count | Domain Exclusivity | **Fine-tuning Model** | **Role & Rationale** |
| :--- | :--- | :---: | :--- | :---: | :--- |
| **Overlapping (Books+Movies)** | booksâ‰¥5 AND moviesâ‰¥5 | 3,000 | N/A | **DualFT-Movies** | **Warm-start**: í’ë¶€í•œ íƒ€ê²Ÿ ì •ë³´ë¡œ ì–‘ë°©í–¥ ì§€ì‹ ì „ì´ ê·¹ëŒ€í™” |
| **Overlapping (Books+Music)** | booksâ‰¥5 AND musicâ‰¥5 | 3,000 | N/A | **DualFT-Music** | **Warm-start**: í’ë¶€í•œ íƒ€ê²Ÿ ì •ë³´ë¡œ ì–‘ë°©í–¥ ì§€ì‹ ì „ì´ ê·¹ëŒ€í™” |
| **Source-only (Movies)** | booksâ‰¥5 AND movies=1 | 3,000 | âœ… music=0 | **SingleFT-Movies** | **Extreme Cold-start**: íƒ€ê²Ÿ ì •ë³´ 1ê°œ. Source ì˜ì¡´ë„ ìµœìƒ (Overfitting ë°©ì§€) |
| **Source-only (Music)** | booksâ‰¥5 AND music=1 | 3,000 | âœ… movies=0 | **SingleFT-Music** | **Extreme Cold-start**: íƒ€ê²Ÿ ì •ë³´ 1ê°œ. Source ì˜ì¡´ë„ ìµœìƒ (Overfitting ë°©ì§€) |
| **Cold-start 2-core (Movies)** | booksâ‰¥5 AND movies=2 | 3,000 | âœ… music=0 | **DualFT-Movies** | **Cold-start**: ìµœì†Œí•œì˜ íƒ€ê²Ÿ íŒ¨í„´(2ê°œ) ì¡´ì¬. Cross-domain íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥ |
| **Cold-start 2-core (Music)** | booksâ‰¥5 AND music=2 | 3,000 | âœ… movies=0 | **DualFT-Music** | **Cold-start**: ìµœì†Œí•œì˜ íƒ€ê²Ÿ íŒ¨í„´(2ê°œ) ì¡´ì¬. Cross-domain íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥ |
| **Cold-start 3-core (Movies)** | booksâ‰¥5 AND movies=3 | 3,000 | âœ… music=0 | **DualFT-Movies** | **Cold-start**: ì ì§„ì  íƒ€ê²Ÿ ì •ë³´ ì¦ê°€. ì¶”ì²œ ì •í™•ë„ ìƒìŠ¹ êµ¬ê°„ |
| **Cold-start 3-core (Music)** | booksâ‰¥5 AND music=3 | 3,000 | âœ… movies=0 | **DualFT-Music** | **Cold-start**: ì ì§„ì  íƒ€ê²Ÿ ì •ë³´ ì¦ê°€. ì¶”ì²œ ì •í™•ë„ ìƒìŠ¹ êµ¬ê°„ |
| **Cold-start 4-core (Movies)** | booksâ‰¥5 AND movies=4 | 3,000 | âœ… music=0 | **DualFT-Movies** | **Mild Cold-start**: 5-core(Warm) ì§„ì… ì§ì „ ë‹¨ê³„ |
| **Cold-start 4-core (Music)** | booksâ‰¥5 AND music=4 | 3,000 | âœ… movies=0 | **DualFT-Music** | **Mild Cold-start**: 5-core(Warm) ì§„ì… ì§ì „ ë‹¨ê³„ |

#### 2. Model Selection Logic

#### A. DualFT Models (DualFT-Movies / DualFT-Music)
* **Target Group:** `Overlapping` (5-core+) ë° `Cold-start` (2, 3, 4-core)
* **í•™ìŠµ ë°ì´í„°:** 12,000 Samples (ê° ë„ë©”ì¸ë³„)
* **ì„ ì • ë…¼ë¦¬:** íƒ€ê²Ÿ ë„ë©”ì¸ ì•„ì´í…œì´ 2ê°œ ì´ìƒ ì¡´ì¬í•  ê²½ìš°, Sourceì™€ Target ê°„ì˜ ì—°ê²° ê³ ë¦¬(Cross-domain Pattern)ë¥¼ ë°œê²¬í•  ìµœì†Œí•œì˜ ë‹¨ì„œê°€ ìˆë‹¤ê³  íŒë‹¨í•˜ì—¬ DualFT ëª¨ë¸ì„ ì ìš©í•©ë‹ˆë‹¤.

#### B. SingleFT Models (SingleFT-Movies / SingleFT-Music)
* **Target Group:** `Source-only` (1-core)
* **í•™ìŠµ ë°ì´í„°:** 3,000 Samples (ê° ë„ë©”ì¸ë³„)
* **ì„ ì • ë…¼ë¦¬:** íƒ€ê²Ÿ ì•„ì´í…œì´ ë‹¨ 1ê°œì¸ ê²½ìš°, ëª¨ë¸ì´ í•´ë‹¹ ì•„ì´í…œ í•˜ë‚˜ì—ë§Œ ê³¼ì í•©(Overfitting)ë˜ê±°ë‚˜ íŒ¨í„´ì„ ì°¾ì§€ ëª»í•  ìœ„í—˜ì´ í½ë‹ˆë‹¤. ë”°ë¼ì„œ Source ë„ë©”ì¸ì˜ ì§€ì‹ì„ Targetìœ¼ë¡œ ì¼ë°©í–¥ ì „ì´í•˜ëŠ” ë° íŠ¹í™”ëœ ë³„ë„ì˜ íŠœë‹ ëª¨ë¸(SingleFT)ì„ ì ìš©í•©ë‹ˆë‹¤.

---

## Dataset Structure (HuggingFace Hub)

```
Training (8 repositories):
  Younggooo/kitrec-dualft_movies-seta     # 12,000 samples
  Younggooo/kitrec-dualft_movies-setb     # 12,000 samples
  Younggooo/kitrec-dualft_music-seta      # 12,000 samples
  Younggooo/kitrec-dualft_music-setb      # 12,000 samples
  Younggooo/kitrec-singleft_movies-seta   # 3,000 samples
  Younggooo/kitrec-singleft_movies-setb   # 3,000 samples
  Younggooo/kitrec-singleft_music-seta    # 3,000 samples
  Younggooo/kitrec-singleft_music-setb    # 3,000 samples

Validation (DPO/GRPOìš©):
  Younggooo/kitrec-val-seta               # 12,000 samples
  Younggooo/kitrec-val-setb               # 12,000 samples

Test:
  Younggooo/kitrec-test-seta              # 30,000 samples
  Younggooo/kitrec-test-setb              # 30,000 samples
```

- **Set A** = Hybrid Candidates (Hard Negatives) - ë‚œì´ë„ ë†’ìŒ
- **Set B** = Random Candidates - ê³µì •í•œ Baseline ë¹„êµìš©

---

## Critical Implementation Notes

### 1. Template Schema Difference (í•„ìˆ˜ í™•ì¸)

| Data Type | Prompt ìœ„ì¹˜ | `instruction` í•„ë“œ | `input` í•„ë“œ |
|-----------|-------------|-------------------|--------------|
| **Training** | `instruction` | ì „ì²´ í”„ë¡¬í”„íŠ¸ (History + Candidates) | ë¹ˆ ë¬¸ìì—´ |
| **Val/Test** | `input` | ì§§ì€ ì„¤ëª… ë¬¸êµ¬ë§Œ | ì „ì²´ í”„ë¡¬í”„íŠ¸ |

**í‰ê°€ ì½”ë“œ ì‘ì„± ì‹œ í•„ìˆ˜ íŒ¨í„´:**
```python
# ì˜¬ë°”ë¥¸ í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
prompt = sample["input"] if sample.get("input") else sample["instruction"]
```

### 1.1 Val/Test Data: ground_truth í•„ë“œ êµ¬ì¡°

| Field | Type | Description | ìš©ë„ |
|-------|------|-------------|------|
| `item_id` | string | GT ì•„ì´í…œ ASIN | ë­í‚¹ í‰ê°€ (Hit@K, MRR, NDCG) |
| `title` | string | ì•„ì´í…œ ì œëª© | ê²€ì¦ìš© |
| `rating` | float | ì‚¬ìš©ì ì‹¤ì œ í‰ì  (1~5) | MAE/RMSE ê³„ì‚° |

**ì˜ˆì‹œ:**
```json
{
  "ground_truth": {
    "item_id": "B07FLGJWKB",
    "title": "Blood Red Roses",
    "rating": 4.0
  }
}
```

**âš ï¸ íŒŒì‹± ì£¼ì˜:** ground_truthê°€ JSON stringì¸ ê²½ìš°ë„ ìˆìœ¼ë¯€ë¡œ ì–‘ìª½ ì²˜ë¦¬ í•„ìš”:
```python
gt = sample.get("ground_truth", {})
if isinstance(gt, str):
    gt = json.loads(gt)
```

### 2. Movies Metadata ëˆ„ë½ ë¬¸ì œ

| ë„ë©”ì¸ | ì´ ì•„ì´í…œ | Title ìˆìŒ | ëˆ„ë½ ë¹„ìœ¨ |
|--------|----------|-----------|----------|
| Books | 352,672 | 352,672 | 0% |
| **Movies** | 468,347 | 265,364 | **43.3%** |
| Music | 339,980 | 339,966 | 0% |

**ì˜í–¥:**
- User Historyì—ì„œ ì¼ë¶€ ì•„ì´í…œì´ `[Item: ID] | Unknown` í˜•íƒœë¡œ í‘œì‹œ
- í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°ì—ëŠ” ì˜í–¥ ì—†ìŒ (GT item_id ê¸°ì¤€)
- Movies ë„ë©”ì¸ ì„±ëŠ¥ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ê²Œ ë‚˜ì˜¬ ê°€ëŠ¥ì„± ìˆìŒ

**ğŸ“Š Sub-group Analysis í•„ìˆ˜ (Movies Domain):**

KitRECì€ í…ìŠ¤íŠ¸(Metadata)ë¥¼ ë³´ê³  ì¶”ë¡ í•˜ëŠ” ëª¨ë¸ì´ë¯€ë¡œ, Unknown ì•„ì´í…œ ì„±ëŠ¥ì´ ë‚®ì€ ê²ƒì€ ë‹¹ì—°í•©ë‹ˆë‹¤. **ë©”íƒ€ë°ì´í„°ê°€ ì˜¨ì „í•  ë•Œ ì„±ëŠ¥ì´ ì••ë„ì ìœ¼ë¡œ ë†’ë‹¤**ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ë©´ ëª¨ë¸ì˜ íš¨ìš©ì„±ì„ ë” ê°•ë ¥í•˜ê²Œ ì¦ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

| Group | ì¡°ê±´ | ë¶„ì„ ëª©ì  |
|-------|------|----------|
| **Group A** | Target Items with Metadata (Title/Category ì¡´ì¬) | KitRECì˜ ì‹¤ì œ ì„±ëŠ¥ |
| **Group B** | Target Items without Metadata (Unknown) | ë©”íƒ€ë°ì´í„° ì˜ì¡´ë„ ì¸¡ì • |

**ì˜ˆìƒ ê²°ê³¼:** Group Aì—ì„œì˜ ì„±ëŠ¥ í–¥ìƒí­ì´ Group Bë³´ë‹¤ í›¨ì”¬ ì»¤ì•¼ í•¨

### 3. Output Parsing ì£¼ì˜ì‚¬í•­

ëª¨ë¸ ì¶œë ¥ í˜•ì‹:
```
<think>
[Chain-of-Thought reasoning]
</think>
```json
{"rank": 1, "item_id": "...", "title": "...", "confidence_score": 9.5, "rationale": "..."}
```

**íŒŒì‹± ì‹œ ê³ ë ¤:**
- `<think>...</think>` ë¸”ë¡ê³¼ JSON ë¸”ë¡ ë¶„ë¦¬ í•„ìš”
- trailing comma ì œê±° ì²˜ë¦¬
- JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ robust fallback êµ¬í˜„
- item_id ì¶œë ¥ ì‹œ candidate list ì— ì—†ëŠ” id ì˜ ê²½ìš° í‰ê°€ì—ì„œ ì œì™¸í•˜ê³  ì–¼ë§ˆë‚˜ ì´ëŸ° ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ”ì§€ ì¶œë ¥ì´ í•„ìš”í•¨
  (	í›„ë³´êµ° ë°– item ì¶œë ¥ ì‹œ â†’ ìë™ fail ì²˜ë¦¬ (rank = âˆ))

### 4. base line User History
 - ì²´í¬ í¬ì¸íŠ¸: ë”¥ëŸ¬ë‹ ë² ì´ìŠ¤ë¼ì¸(CoNet ë“±)ì€ í…ìŠ¤íŠ¸(History Summary)ë¥¼ ì…ë ¥ë°›ì§€ ëª»í•˜ê³  ID ì‹œí€€ìŠ¤ë§Œ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.
 - "Baseline models (CoNet, DTCDR ë“±ë“±) must use the same User History sequences (Item IDs) as defined in the KitREC test set, converted to their specific input format (e.g., ID matrix)." (ì¦‰, KitRECì— ë“¤ì–´ê°€ëŠ” Historyì™€ ë² ì´ìŠ¤ë¼ì¸ì— ë“¤ì–´ê°€ëŠ” Historyê°€ ë™ì¼í•œ ì‹œì ì˜ ë°ì´í„°ì—¬ì•¼ í•¨ì„ ëª…ì‹œ)

---

## Inference Prompt Template (Evaluationìš©)

Test Set í‰ê°€ ì‹œ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì…ë‹ˆë‹¤. Zero-shot baseline ë° Fine-tuned ëª¨ë¸ í‰ê°€ì— ë™ì¼í•˜ê²Œ ì ìš©ë©ë‹ˆë‹¤.

```
# Expert Cross-Domain Recommendation System

You are a specialized recommendation system with expertise in cross-domain knowledge transfer.
Your task is to leverage comprehensive user interaction patterns from source and target domains to rank the **Top 10** most suitable items from the candidate list.

## Input Parameters
- Source Domain: {source_domain}
- Target Domain: {target_domain}
- Task: Rank the top 10 items based on user preference alignment.

## User Interaction History
The user's past interactions contain the Title, Categories, User Rating, and a Summary of the item description.

### User's {source_domain} History:
{source_history_list}
(Format: - {title} | {categories} | Rating: {rating:.1f} | {description_summary})

### User's {target_domain} History:
{target_history_list}
(Format: - {title} | {categories} | Rating: {rating:.1f} | {description_summary})

## List of Available Candidate Items (Total 100):
The candidate items contain the Title, Categories, Average Rating, and a Summary.
[
  (ID: {item_id_1}) {title} | {categories} | Rating: {avg_rating:.1f} | {description_summary}
  (ID: {item_id_2}) {title} | {categories} | Rating: {avg_rating:.1f} | {description_summary}
  ...
  (ID: {item_id_100}) {title} | {categories} | Rating: {avg_rating:.1f} | {description_summary}
]

## Reasoning Guidelines (Thinking Process)
Before generating the final JSON output, you must engage in a deep reasoning process.
Think step-by-step using the following phases:

### Phase 1: Pattern Recognition (Source Domain Analysis)
- Analyze the user's `{source_domain}` history to identify core preference signals.
- Extract key genres, thematic interests, content complexity, and stylistic preferences.
- Identify high-rated items (Rating > 4.0) to understand what the user truly values.

### Phase 2: Cross-Domain Knowledge Transfer
- Apply domain knowledge to map preferences from `{source_domain}` to `{target_domain}`.
- Example: If a user likes "Dark Fantasy Novels" (Source), infer a preference for "Dark/Gothic Atmosphere Movies" (Target).
- Consider semantic connections, author/director styles, and emotional tone.

### Phase 3: Candidate Evaluation & Selection
- Evaluate the 100 candidate items against the transferred profile.
- Select the Top 10 items that best match the inferred preferences.
- Ensure diversity in the selection while maintaining high relevance.
- Formulate a rationale for each selected item.

## Output Format
After your reasoning process, provide results **ONLY** as a JSON array containing the **Top-10** recommended items.
Ensure the **"item_id"** matches the ID provided in the candidate list exactly.

```json
[
   { "rank": 1, "item_id": "...", "title": "...", "confidence_score": <float 1-10>, "rationale": "..." },
   { "rank": 2, "item_id": "...", "title": "...", "confidence_score": <float 1-10>, "rationale": "..." },
   ...
   { "rank": 10, "item_id": "...", "title": "...", "confidence_score": <float 1-10>, "rationale": "..." }
]
```
```

### Template Variables ì„¤ëª…

| Variable | ì„¤ëª… | ì˜ˆì‹œ |
|----------|------|------|
| `{source_domain}` | ì†ŒìŠ¤ ë„ë©”ì¸ | `Books` |
| `{target_domain}` | íƒ€ê²Ÿ ë„ë©”ì¸ | `Movies & TV` ë˜ëŠ” `Music` |
| `{source_history_list}` | ì‚¬ìš©ìì˜ ì†ŒìŠ¤ ë„ë©”ì¸ ì´ë ¥ | Books ì½ì€ ëª©ë¡ |
| `{target_history_list}` | ì‚¬ìš©ìì˜ íƒ€ê²Ÿ ë„ë©”ì¸ ì´ë ¥ | Movies/Music ì‹œì²­/ì²­ì·¨ ëª©ë¡ |
| `{item_id_N}` | í›„ë³´ ì•„ì´í…œ ID (ASIN) | `B07FLGJWKB` |

### 3-Phase Reasoning êµ¬ì¡°

| Phase | ëª©ì  | í•µì‹¬ ì‘ì—… |
|-------|------|----------|
| **Phase 1** | Pattern Recognition | Source ë„ë©”ì¸ì—ì„œ ì„ í˜¸ íŒ¨í„´ ì¶”ì¶œ (ì¥ë¥´, í…Œë§ˆ, ìŠ¤íƒ€ì¼) |
| **Phase 2** | Cross-Domain Transfer | Sourceâ†’Target ë„ë©”ì¸ ì§€ì‹ ì „ì´ (ì˜ë¯¸ì  ì—°ê²°) |
| **Phase 3** | Candidate Evaluation | 100ê°œ í›„ë³´ ì¤‘ Top-10 ì„ ì • ë° rationale ìƒì„± |

---

## Baseline Models & Evaluation Protocols

> **ğŸš¨ ì‹¤í—˜ ê³µì •ì„± í•„ìˆ˜ ì¡°ê±´ (Crucial):**
>
> All baseline models must perform ranking on the **exact same candidate list (1 GT + 99 Negatives)** provided in the KitREC test dataset (`candidate_set`). **Do not use random sampling for baselines during the test phase.**
>
> CoNetì´ë‚˜ DTCDR ê°™ì€ ì „í†µì  ëª¨ë¸ì˜ ì˜¤í”ˆì†ŒìŠ¤ êµ¬í˜„ì²´ë“¤ì€ ë³´í†µ í•™ìŠµ ì‹œ Negative Samplingì„ ëœë¤ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤. KitRECì€ ì–´ë ¤ìš´(Hard) í›„ë³´ë¥¼ í’€ê³ , ë² ì´ìŠ¤ë¼ì¸ì€ ì‰¬ìš´(Random) í›„ë³´ë¥¼ í‘¼ë‹¤ë©´ **ë¹„êµê°€ ë¶ˆê°€ëŠ¥**í•©ë‹ˆë‹¤.

### ë”¥ëŸ¬ë‹ ê¸°ë°˜ CDR

| Model | ì¶œì²˜ | Candidate êµ¬ì„± | í‰ê°€ ë°©ì‹ | í•µì‹¬ ì§€í‘œ |
|-------|------|---------------|----------|----------|
| **CoNet** | CIKM 2018 | test 1 + negative 99 | LOO | Hit@10, NDCG@10 |
| **DTCDR** | CIKM 2019 | test 1 + negative 99 | LOO, Top-N Ranking | HR@10, NDCG@10 |

### LLM ê¸°ë°˜

| Model | ì¶œì²˜ | Candidate êµ¬ì„± | í‰ê°€ ë°©ì‹ | íŠ¹ì§• |
|-------|------|---------------|----------|------|
| **LLM4CDR** | RecSys/WWW 2025 | test 3 + negative 20~30 | Prompt-based Re-ranking | 3ë‹¨ê³„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ |
| **Vanilla Zero-shot** | NIR Paradigm | ì§ì ‘ ìƒì„± | Zero-shot Generation | LLM í•˜í•œì„  (Lower Bound) |

> **ğŸš¨ LLM4CDR Candidate Set ì •ë ¬ í•„ìˆ˜ (Critical):**
>
> LLM4CDR ì› ë…¼ë¬¸ì€ **3 GT + 20~30 Negatives** (ì´ 23~33ê°œ)ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, KitRECì€ **1 GT + 99 Negatives** (ì´ 100ê°œ)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
>
> **ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´ LLM4CDRë„ KitREC í”„ë¡œí† ì½œ(1+99)ë¡œ ì¬í‰ê°€í•´ì•¼ í•©ë‹ˆë‹¤.**
>
> | í”„ë¡œí† ì½œ | LLM4CDR ì› ë…¼ë¬¸ | KitREC (ë³¸ ì—°êµ¬) |
> |---------|----------------|-----------------|
> | Positive | 3ê°œ | 1ê°œ |
> | Negative | 20~30ê°œ | 99ê°œ |
> | ì´ í›„ë³´ ìˆ˜ | 23~33ê°œ | 100ê°œ |
> | ë‚œì´ë„ | ì‰¬ì›€ | ì–´ë ¤ì›€ |
>
> ë…¼ë¬¸ì—ì„œëŠ” "LLM4CDRë¥¼ KitREC í‰ê°€ í”„ë¡œí† ì½œë¡œ ì¬êµ¬í˜„í•˜ì—¬ ë¹„êµ" ëª…ì‹œ í•„ìš”.

### KitREC vs Baseline ë¹„êµ í¬ì¸íŠ¸

| ë¹„êµ í•­ëª© | LLM4CDR | KitREC |
|----------|---------|--------|
| Context Window | í† í° ì œì•½ (íˆìŠ¤í† ë¦¬ 20~40ê°œ) | íŒŒì¸íŠœë‹ìœ¼ë¡œ ê¸´ ë¬¸ë§¥ í•™ìŠµ |
| Hallucination | ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì•„ì´í…œ ì¶”ì²œ ìœ„í—˜ | GT ê¸°ë°˜ íŠœë‹ìœ¼ë¡œ í™˜ê° ì–µì œ |
| í˜•ì‹ ì¤€ìˆ˜ | JSON í˜•ì‹ ë¯¸ì¤€ìˆ˜ ê°€ëŠ¥ | ê²°ê³¼ í˜•íƒœ ì œì–´ ëŠ¥ë ¥ ìš°ìˆ˜ |

### ğŸ“Š í†µê³„ì  ìœ ì˜ì„± ê²€ì • (Statistical Significance Testing)

**ë…¼ë¬¸ ë°œí‘œë¥¼ ìœ„í•´ ëª¨ë“  Baseline ë¹„êµì—ì„œ í†µê³„ì  ìœ ì˜ì„± ë³´ê³  í•„ìˆ˜:**

```python
from scipy import stats
import numpy as np

def paired_t_test(kitrec_scores: list, baseline_scores: list) -> dict:
    """Paired t-test for per-sample metric comparison"""
    t_stat, p_value = stats.ttest_rel(kitrec_scores, baseline_scores)
    effect_size = (np.mean(kitrec_scores) - np.mean(baseline_scores)) / \
                  np.std(np.concatenate([kitrec_scores, baseline_scores]))
    return {
        "t_statistic": t_stat,
        "p_value": p_value,
        "significant_at_0.05": p_value < 0.05,
        "significant_at_0.01": p_value < 0.01,
        "effect_size_cohens_d": effect_size
    }
```

**ì ìš© ë²”ìœ„:**
- RQ1: KitREC-Full vs 3ê°œ Ablation ëª¨ë¸
- RQ2: KitREC vs ëª¨ë“  Baseline (CoNet, DTCDR, LLM4CDR, Vanilla)
- RQ3: User Typeë³„ (1-core ~ 10-core) ì„±ëŠ¥ ì°¨ì´

### ğŸ”’ Baseline Train/Test ë°ì´í„° ë¶„ë¦¬ (Data Leakage ë°©ì§€)

> **âš ï¸ ì¤‘ìš”:** KitREC ë°ì´í„°ì…‹ì€ ì´ë¯¸ Train/Testê°€ ì—„ê²©íˆ ë¶„ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Baseline ëª¨ë¸ í•™ìŠµ ì‹œ ë°˜ë“œì‹œ ì•„ë˜ ë°ì´í„°ì…‹ ë§¤í•‘ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

**Baseline í•™ìŠµìš© ë°ì´í„° (Training):**

| Baseline | Target Domain | Training Dataset | Samples |
|----------|---------------|------------------|---------|
| CoNet/DTCDR | Movies | `Younggooo/kitrec-dualft_movies-seta` | 12,000 |
| CoNet/DTCDR | Movies | `Younggooo/kitrec-dualft_movies-setb` | 12,000 |
| CoNet/DTCDR | Music | `Younggooo/kitrec-dualft_music-seta` | 12,000 |
| CoNet/DTCDR | Music | `Younggooo/kitrec-dualft_music-setb` | 12,000 |

**Baseline í‰ê°€ìš© ë°ì´í„° (Evaluation):**

| Baseline | Target Domain | Test Dataset | Samples |
|----------|---------------|--------------|---------|
| All Baselines | Movies/Music | `Younggooo/kitrec-test-seta` | 30,000 |
| All Baselines | Movies/Music | `Younggooo/kitrec-test-setb` | 30,000 |

**ì˜¬ë°”ë¥¸ Baseline ì‹¤í—˜ í”„ë¡œì„¸ìŠ¤:**

```python
# Step 1: Baseline í•™ìŠµ (Train ë°ì´í„° ì‚¬ìš©)
train_loader = DataLoader("Younggooo/kitrec-dualft_movies-seta", hf_token=args.hf_token)
train_data = train_loader.load_test_data()
trainer.train(train_data)
trainer.save_checkpoint("checkpoints/conet_movies_seta.pt")

# Step 2: Baseline í‰ê°€ (Test ë°ì´í„° ì‚¬ìš© - ë³„ë„ ì‹¤í–‰)
test_loader = DataLoader("Younggooo/kitrec-test-seta", hf_token=args.hf_token)
test_data = test_loader.load_test_data()
evaluator.evaluate(test_data)  # ë°˜ë“œì‹œ Test ë°ì´í„°ë§Œ ì‚¬ìš©
```

> **âŒ ê¸ˆì§€:** Test ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ í•™ìŠµì— ì‚¬ìš©í•˜ëŠ” ê²ƒì€ Data Leakage ì…ë‹ˆë‹¤.
> ```python
> # ì˜ëª»ëœ ì˜ˆì‹œ (Data Leakage)
> train_samples = test_data[:-1000]  # ì ˆëŒ€ ê¸ˆì§€!
> val_samples = test_data[-1000:]
> ```

---

## Research Questions

| RQ | ì—°êµ¬ ì§ˆë¬¸ | KitREC ëª¨ë¸ | ë¹„êµ ëŒ€ìƒ |
|----|---------|------------|----------|
| **RQ1** | KitREC êµ¬ì¡°ì˜ íš¨ê³¼ì„± ê²€ì¦ (Ablation Study) | 2Ã—2 êµì°¨ ê²€ì¦ (ì•„ë˜ ì°¸ì¡°) | - |
| **RQ2** | CDR ë°©ì‹ì˜ íš¨ê³¼ì„± ê²€ì¦ | DualFT-Movies/Music, SingleFT-Movies/Music | CoNet, DTCDR, LLM4CDR, Vanilla NIR |
| **RQ3** | Cold-start/Sparse ë¬¸ì œ í•´ê²° | DualFT Movies/Music (2/3/4-core), SingleFT Movies/Music(1 core)| LLCoNet, DTCDR, LLM4CDR, Vanilla NIRM4CDR |
| **RQ4** | Confidence/Rationale ê²€ì¦ | **KitREC ì „ì²´ ëª¨ë¸ë§Œ** (Baseline ì œì™¸) | Confidence = MAE, RMSE / Rationale = PPL + GPT-4.1 (50ê°œ/ëª¨ë¸) |

### RQ1: 2Ã—2 Ablation Study Design

**ì‹¤í—˜ ëª©ì :** KitRECì˜ ì„±ëŠ¥ í–¥ìƒì´ ë‹¨ìˆœí•œ íŒŒì¸íŠœë‹ ë•ë¶„ì¸ì§€, ì•„ë‹ˆë©´ ì„¤ê³„ëœ Thinking Process(CoT) ë•ë¶„ì¸ì§€ë¥¼ ê²€ì¦

**[í•™ìŠµ ì—¬ë¶€] Ã— [ì¶”ë¡  ë°©ì‹] êµì°¨ ê²€ì¦:**

|  | Thinking (CoT) ì ìš© | Non-Thinking (Direct) ì ìš© |
|--|---------------------|---------------------------|
| **Fine-tuned (KitREC)** | â‘  KitREC-Full (ì œì•ˆ ëª¨ë¸) | â‘¡ KitREC-Direct (Ablation) |
| **Base Model (Untuned)** | â‘¢ Base-CoT (Strong Baseline) | â‘£ Base-Direct (Weak Baseline) |

### RQ1 ë¹„êµ ëª¨ë¸ ìƒì„¸ ì •ì˜

**â‘  KitREC-Full (Proposed Method)**
- Knowledge-Instruction Transfer ë°©ì‹ìœ¼ë¡œ íŒŒì¸íŠœë‹
- ì¶”ë¡  ì‹œ `<think>` íƒœê·¸ë¥¼ í†µí•´ ëª…ì‹œì ì¸ ì¶”ë¡  ê³¼ì • í›„ ì¶”ì²œ ê²°ê³¼ ìƒì„±
- í•™ìŠµ: Reasoning ë°ì´í„° í¬í•¨ / ì¶”ë¡ : Reasoning ìƒì„± í—ˆìš©
- ì¶”ë¡  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿: Inference Prompt Template (Evaluationìš©) ì‚¬ìš©
- **ì—­í• :** ë³¸ ì—°êµ¬ì—ì„œ ì œì•ˆí•˜ëŠ” ìµœì¢… ëª¨ë¸

**â‘¡ KitREC-Direct (Ablation Model)**
- KitREC-Fullê³¼ ë™ì¼í•˜ê²Œ íŒŒì¸íŠœë‹ë˜ì—ˆìœ¼ë‚˜, Thinking ê³¼ì • ì œê±°
- êµ¬í˜„ ë°©ë²•:
  - (A) í•™ìŠµ ë°ì´í„°ì—ì„œ `<think>` ë¶€ë¶„ì„ ì œê±°í•˜ê³  í•™ìŠµí•œ ë³„ë„ ëª¨ë¸ (ê¶Œì¥)
  - (B) í•™ìŠµì€ ë™ì¼í•˜ë˜ ì¶”ë¡  ì‹œ í”„ë¡¬í”„íŠ¸ë¡œ Thinking ìƒì„± ì–µì œ
- ì¶”ë¡  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿: Inference Prompt Template (Evaluationìš©) ì‚¬ìš©
- **ì—­í• :** "íŒŒì¸íŠœë‹ì€ í–ˆì§€ë§Œ ì¶”ë¡  ê³¼ì •ì´ ì—†ì„ ë•Œ"ì˜ ì„±ëŠ¥ ì¸¡ì • â†’ Thinking Processì˜ ê¸°ì—¬ë„ ì¦ëª…

**â‘¢ Base-CoT (Zero-shot Chain-of-Thought)**
- íŒŒì¸íŠœë‹ ë˜ì§€ ì•Šì€ Qwen3-14B-Instruct (Original) ëª¨ë¸
- ì¶”ë¡  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿: Inference Prompt Template (Evaluationìš©) ì‚¬ìš©
- **ì—­í• :** íŒŒì¸íŠœë‹ ì—†ì´ LLM ë³¸ì—°ì˜ ì¶”ë¡  ëŠ¥ë ¥ë§Œìœ¼ë¡œ ì–´ë””ê¹Œì§€ ê°€ëŠ¥í•œì§€ ì¸¡ì • â†’ Tuningì˜ íš¨ìš©ì„± ì¦ëª…

**â‘£ Base-Direct (Vanilla Zero-shot)**
- íŒŒì¸íŠœë‹ ë˜ì§€ ì•Šì€ Qwen3-14B-Instruct (Original) ëª¨ë¸
- ì¶”ë¡  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿: Inference Prompt Template (Evaluationìš©) ì‚¬ìš©
- Reasoning ê³¼ì • ì—†ì´ ê³§ë°”ë¡œ ì¶”ì²œ ëª©ë¡ ìƒì„±
- **ì—­í• :** ê°€ì¥ ê¸°ë³¸ì ì¸ Baseline (Lower Bound)

â€» Note for Direct Models (â‘¡, â‘£): For KitREC-Direct and Base-Direct, use the same template but REMOVE the ## Reasoning Guidelines section entirely. The model should output the JSON directly without the <think> block.

---

## Model Architecture

- **Base Model**: Qwen/Qwen3-14B
- **Fine-tuning**: PEFT QLoRA (4-bit NF4 quantization)
- **Target Modules**: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj

### Hyperparameters

| Parameter | DualFT (12K samples) | SingleFT (3K samples) |
|-----------|---------------------|----------------------|
| LoRA r | 32 | 24 |
| LoRA alpha | 64 | 48 |
| LoRA dropout | 0.08 | 0.15 |
| Learning Rate | 2e-4 | 6e-5 |
| **warmup_ratio** | **0.05** | **0.1** |
| Epochs | 3 | 6 |
| Batch Size | 4 (effective 32) | 2 (effective 32) |
| NEFTune Alpha | 5.0 | 3.0 |
| Weight Decay | 0.02 | 0.05 |
| Label Smoothing | 0.05 | 0.1 |

---

## Environment

- **Training**: RunPod A100/H100 80GB
- **Inference/Evaluation**: vLLM ê¸°ë°˜, Nvidia 5090 (36GB VRAM)
- **Framework**: HuggingFace Transformers + PEFT + bitsandbytes
- **Python Packages**: torch>=2.2.0, transformers==4.57.3, peft==0.13.0

---

## Implementation Status (2025-12-07 Updated)

### âœ… Phase 1: Critical Issues (ì™„ë£Œ)

| í•­ëª© | ìƒíƒœ | íŒŒì¼ | ì„¤ëª… |
|------|------|------|------|
| Confidence Score 1-10 ë²”ìœ„ | âœ… | `baselines/*/evaluator.py` | `sigmoid * 9 + 1` ì •ê·œí™” |
| Train/Test ë¶„ë¦¬ | âœ… | `scripts/run_baseline_eval.py` | Data Leakage ë°©ì§€ |
| User Type Mapping | âœ… | `baselines/dtcdr/evaluator.py` | RQ3 Cold-start ë¶„ì„ |
| Candidate Set ê²€ì¦ | âœ… | `baselines/base_evaluator.py` | 100ê°œ í›„ë³´ + GT í¬í•¨ ê²€ì¦ |

### âœ… Phase 2: High Priority (ì™„ë£Œ)

| í•­ëª© | ìƒíƒœ | íŒŒì¼ | ì„¤ëª… |
|------|------|------|------|
| Device mismatch | âœ… | `baselines/*/model.py` | `model_device` ì‚¬ìš© |
| Gradient Clipping | âœ… | `baselines/*/trainer.py` | `max_norm=1.0` |
| Statistical Significance | âœ… | `src/metrics/statistical_analysis.py` | Paired t-test, Holm correction |
| DIRECT_TEMPLATE ê°œì„  | âœ… | `src/data/prompt_builder.py` | Confidence ê°€ì´ë“œ ì¶”ê°€ |

### âœ… Phase 3: Medium Priority (ì™„ë£Œ)

| í•­ëª© | ìƒíƒœ | íŒŒì¼ | ì„¤ëª… |
|------|------|------|------|
| LLM4CDR Target History | âœ… | `baselines/llm4cdr/prompts.py` | KitREC êµ¬ì¡° ë§ì¶¤ + ì°¨ì´ì  ë¬¸ì„œí™” |
| LR Scheduler | âœ… | `baselines/*/trainer.py` | `ReduceLROnPlateau` |
| Holm Correction | âœ… | `src/metrics/statistical_analysis.py` | Step-up enforcement ìˆ˜ì • |
| ë¬´í•œë£¨í”„ ë°©ì§€ | âœ… | `baselines/*/trainer.py` | Negative sampling ì œí•œ |

### âœ… Phase 4: ExplainabilityMetrics (ì™„ë£Œ)

| í•­ëª© | ìƒíƒœ | íŒŒì¼ | ì„¤ëª… |
|------|------|------|------|
| MAE/RMSE ê³„ì‚° | âœ… | `src/metrics/explainability_metrics.py` | Confidence vs GT Rating |
| Perplexity ê³„ì‚° | âœ… | `src/metrics/explainability_metrics.py` | Rationale í’ˆì§ˆ í‰ê°€ |
| **GPT-4.1 Evaluation** | âœ… | `src/metrics/explainability_metrics.py` | User Typeë³„ ê· ë“± ì¶”ì¶œ, ëª¨ë¸ë‹¹ 50ê°œ |

---

## GPT-4.1 Rationale Quality Evaluation (RQ4)

### ê°œìš”

User Typeë³„ ê· ë“± ì¶”ì¶œ(Stratified Sampling)ë¡œ ëª¨ë¸ë‹¹ 50ê°œ ìƒ˜í”Œì„ GPT-4.1 APIë¡œ í‰ê°€í•©ë‹ˆë‹¤.
- **ìƒ˜í”Œë§ ë°©ì‹**: 10ê°œ User Type Ã— 5ê°œ/Type = 50ê°œ/ëª¨ë¸
- **ëª©ì **: ë¹„ìš© íš¨ìœ¨ì ì´ë©´ì„œ User Typeë³„ ê· í˜• ì¡íŒ í‰ê°€

> âš ï¸ **RQ4 í‰ê°€ ëŒ€ìƒ**: KitREC ëª¨ë¸ë§Œ (Baseline ì œì™¸)
> - Baseline(CoNet, DTCDR, LLM4CDR)ì€ RQ4(Explainability)ì—ì„œ **ì œì™¸**
> - Baselineì€ Confidence Score/MAE/RMSE ê³„ì‚° ë¶ˆí•„ìš”

### í‰ê°€ ê¸°ì¤€ (1-10ì )

| ê¸°ì¤€ | ì˜ë¬¸ | ì„¤ëª… |
|------|------|------|
| **ë…¼ë¦¬ì„±** | Logic | ì¶”ì²œ ì´ìœ ê°€ ë…¼ë¦¬ì ì¸ê°€? |
| **êµ¬ì²´ì„±** | Specificity | êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•˜ëŠ”ê°€? |
| **Cross-domain ì—°ê²°ì„±** | Cross-domain | Sourceâ†’Target ì—°ê²°ì´ ëª…í™•í•œê°€? |
| **ì„ í˜¸ ë°˜ì˜** | Preference | ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ë¥¼ ì˜ ë°˜ì˜í–ˆëŠ”ê°€? |

### ì‚¬ìš©ë²•

```python
from src.metrics.explainability_metrics import GPTRationaleEvaluator

# GPT í‰ê°€ê¸° ì´ˆê¸°í™” (OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”)
# samples_per_type=5: ê° User Typeë‹¹ 5ê°œ ìƒ˜í”Œ (ì´ 50ê°œ/ëª¨ë¸)
evaluator = GPTRationaleEvaluator(samples_per_type=5)

if evaluator.is_available():
    # User Typeë³„ ê· ë“± ì¶”ì¶œ í›„ í‰ê°€
    rationale_scores = evaluator.evaluate_batch(results)
    print(f"Logic: {rationale_scores['logic']:.2f}/10")
    print(f"Overall: {rationale_scores['overall']:.2f}/10")
    print(f"Sampling Stats: {rationale_scores['sampling_stats']}")
```

### í™˜ê²½ ì„¤ì •

```bash
export OPENAI_API_KEY="your-api-key"
```

---

## User Typeë³„ Cold-start Analysis (RQ3)

### í•µì‹¬ ì—°êµ¬ í¬ì¸íŠ¸

> **â­ KitRECì˜ í•µì‹¬ ê°•ì :** ê¸°ì¡´ CDR ëª¨ë¸ë“¤ì€ 5-core ì´ìƒì—ì„œë§Œ ì‹¤í—˜í•˜ì§€ë§Œ, KitRECì€ 1-core (ê·¹í•œ Cold-start)ì—ì„œë„ ì„±ëŠ¥ì´ ë‚˜ì˜µë‹ˆë‹¤.

### Core Levelë³„ í‰ê°€

```python
from scripts.run_baseline_eval import build_user_type_mapping, print_user_type_metrics

# User Type ë§¤í•‘ ìƒì„±
user_type_mapping = build_user_type_mapping(original_samples, converter)

# Core Levelë³„ í‰ê°€
metrics_by_user_type = evaluator.evaluate_by_user_type(samples, user_type_mapping)

# ê²°ê³¼ ì¶œë ¥ (1-core ~ 10+-core)
print_user_type_metrics(metrics_by_user_type, "DTCDR")
```

### Core Level ì •ì˜

| Core Level | ì¡°ê±´ | íŠ¹ì„± | ë¹„êµ ì˜ë¯¸ |
|------------|------|------|----------|
| 1-core | target=1 | ê·¹í•œ Cold-start | KitRECë§Œ ì‹¤í—˜ ê°€ëŠ¥ |
| 2-core | target=2 | ì‹¬ê°í•œ Cold-start | ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ ê¸‰ë½ |
| 3-core | target=3 | ì¤‘ê°„ Cold-start | íŒ¨í„´ ì‹œì‘ì  |
| 4-core | target=4 | ê²½ë¯¸í•œ Cold-start | 5-core ì§„ì… ì§ì „ |
| 5-9 core | target=5~9 | Warm-start | ì¼ë°˜ì  ì‹¤í—˜ ì¡°ê±´ |
| 10+-core | targetâ‰¥10 | í’ë¶€í•œ ë°ì´í„° | ëŒ€ë¶€ë¶„ ëª¨ë¸ ì„±ëŠ¥ ì¢‹ìŒ |

---

## Statistical Significance Testing

### í†µê³„ì  ìœ ì˜ì„± ê²€ì • êµ¬í˜„

```python
from src.metrics.statistical_analysis import StatisticalAnalysis

stat = StatisticalAnalysis()

# 1. Paired t-test
result = stat.paired_t_test(kitrec_scores, baseline_scores)
print(f"p-value: {result['p_value']:.4f}")
print(f"Cohen's d: {result['effect_size_cohens_d']:.3f}")

# 2. ë‹¤ì¤‘ ë¹„êµ ë³´ì • (Holm-Bonferroni)
p_values = [result1['p_value'], result2['p_value'], result3['p_value']]
corrected = stat.apply_multiple_correction(p_values, method="holm")

# 3. ë…¼ë¬¸ìš© í˜•ì‹
formatted = stat.format_for_paper(result)  # e.g., "+0.123**"
```

### Effect Size í•´ì„

| Cohen's d | í•´ì„ |
|-----------|------|
| 0.2 | Small |
| 0.5 | Medium |
| 0.8 | Large |

---

## LLM4CDR vs KitREC êµ¬í˜„ ì°¨ì´ì 

### ì£¼ìš” ì°¨ì´ì  (ë…¼ë¬¸ ëª…ì‹œ í•„ìš”)

| í•­ëª© | LLM4CDR ì› ë…¼ë¬¸ | KitREC êµ¬í˜„ |
|------|----------------|-------------|
| **Candidate Set** | 3 GT + 20~30 Neg (ì´ ~30ê°œ) | 1 GT + 99 Neg (ì´ 100ê°œ) |
| **Target History** | ë¯¸ì‚¬ìš© | í¬í•¨ (ê³µì •í•œ ë¹„êµ) |
| **Stage 1 Caching** | ë™ì¼ | ë™ì¼ |
| **3-Stage Pipeline** | ë™ì¼ | ë™ì¼ |

### ë…¼ë¬¸ ì‘ì„± ì‹œ ëª…ì‹œ ì‚¬í•­

```
LLM4CDR was re-evaluated using the KitREC evaluation protocol
(1 GT + 99 negatives) for fair comparison. The original LLM4CDR
uses a smaller candidate set (3 GT + 20-30 negatives).
```

---

## Baseline ê³µí†µ ì¸í”„ë¼

### BaseEvaluator í´ë˜ìŠ¤

ëª¨ë“  ë² ì´ìŠ¤ë¼ì¸ í‰ê°€ê¸°ê°€ ê³µìœ í•˜ëŠ” ê³µí†µ ê¸°ëŠ¥:

```python
# baselines/base_evaluator.py
class BaseEvaluator:
    def validate_candidate_set(candidates, gt_id):
        """100ê°œ í›„ë³´ + GT í¬í•¨ ê²€ì¦"""

    def normalize_confidence(raw_score):
        """[0,1] â†’ [1,10] ì •ê·œí™”: sigmoid * 9 + 1"""

    def calculate_metrics(gt_rank):
        """ê³µí†µ ë©”íŠ¸ë¦­ ê³„ì‚° (Hit@K, MRR, NDCG@K)"""
```

### í•™ìŠµ/í‰ê°€ ë°ì´í„° ë¶„ë¦¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] Training: `kitrec-dualft_*` ë°ì´í„°ì…‹ ì‚¬ìš©
- [x] Evaluation: `kitrec-test-*` ë°ì´í„°ì…‹ ì‚¬ìš©
- [x] Data Leakage ë°©ì§€: Test ë°ì´í„° ë¶„í• í•˜ì—¬ í•™ìŠµ ê¸ˆì§€
- [x] Checkpoint ì €ì¥/ë¡œë“œ: Scheduler state í¬í•¨

---

## ë²„ê·¸ ìˆ˜ì • ê¸°ë¡ (2025-12-07)

### ìˆ˜ì •ëœ ì´ìŠˆ

| ì´ìŠˆ | íŒŒì¼ | ìˆ˜ì • ë‚´ìš© |
|------|------|----------|
| Path validation ê´„í˜¸ | `baselines/*/trainer.py` | ì—°ì‚°ì ìš°ì„ ìˆœìœ„ ëª…í™•í™” |
| ë¬´í•œë£¨í”„ ê°€ëŠ¥ì„± | `baselines/*/trainer.py` | `max_attempts` ì œí•œ ì¶”ê°€ |
| Device mismatch | `baselines/*/model.py` | `model_device` ì‚¬ìš© |
| Holm correction | `statistical_analysis.py` | Step-up enforcement |
| Empty list ì²˜ë¦¬ | `baselines/dtcdr/trainer.py` | ì•ˆì „í•œ max() í˜¸ì¶œ |

### ì¶”ê°€ ê°œì„  ì‚¬í•­ (2025-12-07 Updated)

| ì´ìŠˆ ID | íŒŒì¼ | ìˆ˜ì • ë‚´ìš© | ëª©ì  |
|---------|------|----------|------|
| A-1 | `llm4cdr/evaluator.py` | BaseEvaluator ìƒì† ì¶”ê°€ | ê³µí†µ ì¸í”„ë¼ í™œìš© |
| A-1 | `llm4cdr/evaluator.py` | Candidate Set ê²€ì¦ (100ê°œ + GT í¬í•¨) | ì‹¤í—˜ ê³µì •ì„± ë³´ì¥ |
| A-1 | `llm4cdr/evaluator.py` | Confidence Score ì •ê·œí™” (1-10 ë²”ìœ„) | ë©”íŠ¸ë¦­ ì¼ê´€ì„± |
| A-2 | `baselines/*/evaluator.py` | per-sample metrics ìˆ˜ì§‘ | t-test í†µê³„ ê²€ì • ì§€ì› |
| A-3 | `base_evaluator.py` | ê²€ì¦ ì‹¤íŒ¨ ì‹œ logging ì¶”ê°€ | ëŠ¥ë™ì  ì˜¤ë¥˜ íƒì§€ |

---

## per-sample Metrics í™œìš© (í†µê³„ì  ìœ ì˜ì„± ê²€ì •)

### ëª¨ë“  Evaluatorì—ì„œ per-sample ë©”íŠ¸ë¦­ ìˆ˜ì§‘

ëª¨ë“  ë² ì´ìŠ¤ë¼ì¸ í‰ê°€ê¸°(CoNet, DTCDR, LLM4CDR)ì—ì„œ ê°œë³„ ìƒ˜í”Œë³„ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤:

```python
# evaluator.evaluate() ë°˜í™˜ê°’
result = evaluator.evaluate(samples)

# ì§‘ê³„ëœ ë©”íŠ¸ë¦­
print(f"Hit@10: {result['hit@10']:.4f}")
print(f"NDCG@10: {result['ndcg@10']:.4f}")

# per-sample ë©”íŠ¸ë¦­ (í†µê³„ ê²€ì •ìš©)
per_sample = result["per_sample"]  # {"hit@10": [...], "ndcg@10": [...], "mrr": [...]}

# Paired t-test ì‹¤í–‰
from src.metrics.statistical_analysis import StatisticalAnalysis
stat = StatisticalAnalysis()
comparison = stat.paired_t_test(kitrec_per_sample["hit@10"], baseline_per_sample["hit@10"])
print(f"p-value: {comparison['p_value']:.4f}")
```

### LLM4CDR íŠ¹ìˆ˜ ê¸°ëŠ¥

LLM4CDR í‰ê°€ê¸°ëŠ” ì¶”ê°€ë¡œ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

```python
# í‰ê°€ í†µê³„ ì¡°íšŒ
stats = evaluator.get_statistics()
print(f"ê²€ì¦ ì‹¤íŒ¨ ìƒ˜í”Œ ìˆ˜: {stats['validation_failures']}")
print(f"ë¬´íš¨ ì˜ˆì¸¡ ìˆ˜: {stats['total_invalid_predictions']}")
print(f"í‰ê°€ëœ ìƒ˜í”Œ ìˆ˜: {stats['samples_evaluated']}")

# User Typeë³„ per-sample ë©”íŠ¸ë¦­ë„ ìë™ ìˆ˜ì§‘
evaluator.per_sample_metrics  # {user_id: {metric: value}}
```
