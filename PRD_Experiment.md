# Experimental_test í‰ê°€ ì§„í–‰ê³¼ì • ì„¤ëª…

## huggingface ì˜ ëª¨ë¸ê´´ ë°ì´í„°ë¥¼ ì½ì–´ë“¤ì—¬ kitec í‰ê°€ë¥¼ ì§„í–‰í•¨

## KITREC ì˜ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸
 - @baselinemodel.md íŒŒì¼ ì°¸ì¡°
 - CoNet, DTCRD, LLM4CDR 

## í‰ê°€ì§€í‘œ :
### KITREC ì˜ ì¶”ì²œ ì•„ì´í…œ ì„±ëŠ¥ í‰ê°€ ë° ë² ì´ìŠ¤ë¼ì¸(ëª¨ë¸ ë¹„êµ) í‰ê°€ ê¸°ì¤€ 
 - Hit@1 : ì •í™•íˆ 1ìœ„ë¡œ ì˜ˆì¸¡ / 0~100%
 - Hit@5 : Top-5 ì•ˆì— ì •ë‹µ í¬í•¨ / 0~100%
 - Hit@10 : Top-10 ì•ˆì— ì •ë‹µ í¬í•¨ / 0~100%  -> Hit@10:  "Top-10ì— ìˆë‚˜ìš”?"  â†’  ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0
 - MRR (Mean Reciprocal Rank): ì˜ˆì¸¡ ë¦¬ìŠ¤íŠ¸ì—ì„œ ëª‡ ë²ˆì§¸ì— ë‚˜íƒ€ë‚˜ëŠ”ì§€ í‰ê°€
    ìˆœìœ„ | Reciprocal Rank
    1ìœ„ | 1.000
    2ìœ„ | 0.500
    3ìœ„ | 0.333
    5ìœ„ | 0.200
    10ìœ„ | 0.100
    íŠ¹ì§•: ìƒìœ„ ìˆœìœ„ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬ (1ìœ„ ì˜ˆì¸¡ì´ ë§¤ìš° ì¤‘ìš”)
 - NDCG@5  : Top-5 ì— ë­í‚¹í’ˆì§ˆ
 - NDCG@10 : Top-10 ì— ë­í‚¹í’ˆì§ˆ(ë…¼ë¬¸ í‘œì¤€) -> "Top-10ì—ì„œ ìˆœìœ„ í’ˆì§ˆì€?"  â†’  ìˆœìœ„ì— ë”°ë¼ 0.29~1.0
    ìˆœìœ„ | NDCG@10
    1ìœ„  | 1.000
    2ìœ„  | 0.631
    3ìœ„  | 0.500
    5ìœ„  | 0.387
    10ìœ„ | 0.289
    íŠ¹ì§•: ë¡œê·¸ í• ì¸ìœ¼ë¡œ ìˆœìœ„ê°€ ë‚®ì•„ì§ˆìˆ˜ë¡ ê°ì†Œí­ì´ ì¤„ì–´ë“¦

### USER TYPE ë³„ ì¶”ì²œì•„ì´í…œ ì„±ëŠ¥í‰ê°€
#### CORE LEVEL í‰ê°€
| Target Core | User Type | Count per Domain | ì„¤ëª… |
|-------------|-----------|------------------|------|
| **1-core** | source_only | 3,000 | ê·¹í•œ Cold-start (target=1) |
| **2-core** | cold_start_2core | 3,000 | ì‹¬ê°í•œ Cold-start (target=2) |
| **3-core** | cold_start_3core | 3,000 | ì¤‘ê°„ Cold-start (target=3) |
| **4-core** | cold_start_4core | 3,000 | ê²½ë¯¸í•œ Cold-start (target=4) |
| **5-core** | overlapping (target=5~9) | í•„í„°ë§ í•„ìš” | Warm ì‹œì‘ (targetâ‰¥5) |
| **10-core** | overlapping (targetâ‰¥10) | í•„í„°ë§ í•„ìš” | í’ë¶€í•œ Target (targetâ‰¥10) |

#### ë°ì´í„° ì„¤ëª…
```
Younggooo/kitrec-dualft_movies-seta     # 12,000 samples
Younggooo/kitrec-dualft_movies-setb     # 12,000 samples
Younggooo/kitrec-dualft_music-seta      # 12,000 samples
Younggooo/kitrec-dualft_music-setb      # 12,000 samples
Younggooo/kitrec-singleft_movies-seta   # 3,000 samples
Younggooo/kitrec-singleft_movies-setb   # 3,000 samples
Younggooo/kitrec-singleft_music-seta    # 3,000 samples
Younggooo/kitrec-singleft_music-setb    # 3,000 samples
```
**Validation Data (2 repositories):** (ì¶”í›„ DPO, RLVR ì— í™œìš©í•  ì˜ˆì •)
```
Younggooo/kitrec-val-seta               # 12,000 samples
Younggooo/kitrec-val-setb               # 12,000 samples
```

**Test Data (2 repositories):**
```
Younggooo/kitrec-test-seta              # 30,000 samples
Younggooo/kitrec-test-setb              # 30,000 samples
```
aining Datasets (8 repositories):*
- https://huggingface.co/datasets/Younggooo/kitrec-dualft_movies-seta
- https://huggingface.co/datasets/Younggooo/kitrec-dualft_movies-setb
- https://huggingface.co/datasets/Younggooo/kitrec-dualft_music-seta
- https://huggingface.co/datasets/Younggooo/kitrec-dualft_music-setb
- https://huggingface.co/datasets/Younggooo/kitrec-singleft_movies-seta
- https://huggingface.co/datasets/Younggooo/kitrec-singleft_movies-setb
- https://huggingface.co/datasets/Younggooo/kitrec-singleft_music-seta
- https://huggingface.co/datasets/Younggooo/kitrec-singleft_music-setb


*Validation Datasets (2 repositories):*(ì¶”í›„ DPO, RLVR ì— í™œìš©í•  ì˜ˆì •)
- https://huggingface.co/datasets/Younggooo/kitrec-val-seta
- https://huggingface.co/datasets/Younggooo/kitrec-val-setb


*Test Datasets (2 repositories):*
- https://huggingface.co/datasets/Younggooo/kitrec-test-seta
- https://huggingface.co/datasets/Younggooo/kitrec-test-setb


### KIREC ì˜ ì¶”ì²œ ì„¤ëª…ë ¥ í‰ê°€ 
#### [ "confidence": 9.5 ] ì™€ ê°™ì€ ì¶”ì²œ ì‹ ë¢° ì ìˆ˜ í‰ê°€
 - ì •ë‹µ ì•„ì´í…œì˜ Rating ê³¼ í‰ê· ê³„ì—´ í‰ê°€ ì§€í‘œë¡œ ë¹„êµ
 - TESTë°ì´í„° ìƒì—ì„œëŠ” 5ì  ë§Œì , Prediction confidence float í˜•íƒœì˜ 0~10 ì ì— ëŒ€í•œ ì •ê·œí™”ê°€ í•„ìš”í•¨
 - Rating Prediction based :  MAE, RMSE

#### [ "rationale": "ì—­ì‚¬ ì†Œì„¤ ì„ í˜¸ë„ì™€ ì—°ê³„ëœ..." ] ì™€ ê°™ì€ ì¶”ì²œ ì„¤ëª…ë ¥ í‰ê°€ 
 - Perplexity(PPL) : ì¶”ì²œ ì„¤ëª…ì— ëŒ€í•œ í‰ê°€ì§€í‘œë¡œ ì‚¬ìš©
 - í¼í”Œë ‰ì‹œí‹°ëŠ” **"LLMì´ ì–¼ë§ˆë‚˜ í™•ì‹ ì„ ê°€ì§€ê³  ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ”ê°€"**ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œì´ë¯€ë¡œ rationale ì— í‰ê°€ì§€í‘œë¡œ ì‚¬ìš©í•¨


### ì‹¤í—˜ í‰ê°€ ì§„í–‰ í™˜ê²½
 - vllm ê¸°ë°˜
 - Nvida 5090 vram 36GB í™˜ê²½
  - VENV í™˜ê²½ìœ¼ë¡œ Kitec í‰ê°€ì‹¤í—˜ì„ ì§„í–‰í•  ì˜ˆì •ì„



# (ë¶€ê°€ì„¤ëª…) KitREC Fine-tuning PRD (Product Requirements Document)
## Key Decisions (Finalized)

| í•­ëª© | ê²°ì • ì‚¬í•­ |
|------|----------|
| **Train/Val Split** | ì½”ë“œ ë‚´ë¶€ 90/10 stratified split (user_type ê¸°ì¤€) |
| **SingleFT ì´ˆê¸°í™”** | Base Model(Qwen3-14B) ë…ë¦½ í•™ìŠµ (DualFT ì²´í¬í¬ì¸íŠ¸ ë¯¸ì‚¬ìš©) |
| **Thinking í•™ìŠµ** | `<think>...</think>` í¬í•¨ ì „ì²´ output í•™ìŠµ (Chain-of-Thought) |
| **ë°ì´í„° ì œê³µ** | HuggingFace Hub ì—…ë¡œë“œ â†’ RunPodì—ì„œ ë‹¤ìš´ë¡œë“œ |
| **êµ¬í˜„ ë²”ìœ„** | ì „ì²´ íŒŒì´í”„ë¼ì¸ (train, evaluate, upload_to_hub) |

---

## 1. Overview

### 1.1 Project Summary

KitREC (Knowledge-Instruction Transfer for Recommendation) Fine-tuning í”„ë¡œì íŠ¸ëŠ” Cross-Domain Recommendationì„ ìœ„í•´ Qwen3-14B ëª¨ë¸ì„ PEFT QLoRA ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.

**í•µì‹¬ ëª©í‘œ:**
- Source Domain(Books)ì˜ í’ë¶€í•œ ì´ë ¥ìœ¼ë¡œ Target Domain(Movies/Music)ì˜ Cold-start ë¬¸ì œ í•´ê²°
- 4ê°œ Fine-tuning ëª¨ë¸ì„ í†µí•œ ì²´ê³„ì ì¸ Cross-Domain Transfer í•™ìŠµ
- Set A(Hard Negatives) vs Set B(Random) A/B Testingìœ¼ë¡œ ì‹¤í—˜ ê³µì •ì„± í™•ë³´

### 1.2 Hardware & Infrastructure

| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| **GPU** | RunPod A100 80GB VRAM ë˜ëŠ” H100 80GB |
| **Training Framework** | Hugging Face Transformers + PEFT |
| **Data Storage** | Hugging Face Hub |
| **Model Storage** | Hugging Face Hub (Fine-tuned models) |
| **Working Directory** | `./finetuning/` |

---

## 2. Instruction Data Structure

### 2.1 Directory Structure (Set-Centric View)

Fine-tuningì— ì‚¬ìš©í•  **Set ì¤‘ì‹¬ ë°ì´í„° êµ¬ì¡°**ì…ë‹ˆë‹¤. Set A/B í•˜ìœ„ì— ëª¨ë¸ë³„ Train ë°ì´í„°ê°€ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

```
./dataprocess/data/instruction/
â”‚
â”œâ”€â”€ setA/                                      # â­ Set A: Hybrid Candidates (Hard Negatives)
â”‚   â”‚
â”‚   â”œâ”€â”€ train.jsonl                            # 30,000 samples (717MB) - ì „ì²´ Train
â”‚   â”‚
â”‚   â”œâ”€â”€ by_model/                              # ğŸ“ ëª¨ë¸ë³„ Train ë°ì´í„° (SFT í•™ìŠµìš©)
â”‚   â”‚   â”œâ”€â”€ dualft_movies.jsonl                # 12,000 samples - Movies & TV ì¶”ì²œ
â”‚   â”‚   â”œâ”€â”€ dualft_music.jsonl                 # 12,000 samples - Music ì¶”ì²œ
â”‚   â”‚   â”œâ”€â”€ singleft_movies.jsonl              # 3,000 samples - Movies ê·¹í•œ Cold-start
â”‚   â”‚   â””â”€â”€ singleft_music.jsonl               # 3,000 samples - Music ê·¹í•œ Cold-start
â”‚   â”‚
â”‚   â”œâ”€â”€ val.jsonl                              # 12,000 samples (142MB) - DPO/GRPOìš©
â”‚   â””â”€â”€ test.jsonl                             # 30,000 samples (351MB) - ì‹¤í—˜ ê²°ê³¼ìš©
â”‚
â””â”€â”€ setB/                                      # â­ Set B: Random Candidates (Fair Baseline)
    â”‚
    â”œâ”€â”€ train.jsonl                            # 30,000 samples (716MB) - ì „ì²´ Train
    â”‚
    â”œâ”€â”€ by_model/                              # ğŸ“ ëª¨ë¸ë³„ Train ë°ì´í„° (SFT í•™ìŠµìš©)
    â”‚   â”œâ”€â”€ dualft_movies.jsonl                # 12,000 samples - Movies & TV ì¶”ì²œ
    â”‚   â”œâ”€â”€ dualft_music.jsonl                 # 12,000 samples - Music ì¶”ì²œ
    â”‚   â”œâ”€â”€ singleft_movies.jsonl              # 3,000 samples - Movies ê·¹í•œ Cold-start
    â”‚   â””â”€â”€ singleft_music.jsonl               # 3,000 samples - Music ê·¹í•œ Cold-start
    â”‚
    â”œâ”€â”€ val.jsonl                              # 12,000 samples (146MB) - DPO/GRPOìš©
    â””â”€â”€ test.jsonl                             # 30,000 samples (362MB) - ì‹¤í—˜ ê²°ê³¼ìš©
```

### 2.2 Data File Summary

| Set | íŒŒì¼ | Samples | Size | ìš©ë„ |
|-----|------|---------|------|------|
| **Set A** | `setA/by_model/dualft_movies.jsonl` | 12,000 | - | SFT í•™ìŠµ (DualFT-Movies) |
| **Set A** | `setA/by_model/dualft_music.jsonl` | 12,000 | - | SFT í•™ìŠµ (DualFT-Music) |
| **Set A** | `setA/by_model/singleft_movies.jsonl` | 3,000 | - | SFT í•™ìŠµ (SingleFT-Movies) |
| **Set A** | `setA/by_model/singleft_music.jsonl` | 3,000 | - | SFT í•™ìŠµ (SingleFT-Music) |
| **Set A** | `setA/val.jsonl` | 12,000 | 142MB | DPO/GRPO (ì¶”í›„) |
| **Set A** | `setA/test.jsonl` | 30,000 | 351MB | ì‹¤í—˜ ê²°ê³¼ í‰ê°€ |
| **Set B** | `setB/by_model/dualft_movies.jsonl` | 12,000 | - | SFT í•™ìŠµ (DualFT-Movies) |
| **Set B** | `setB/by_model/dualft_music.jsonl` | 12,000 | - | SFT í•™ìŠµ (DualFT-Music) |
| **Set B** | `setB/by_model/singleft_movies.jsonl` | 3,000 | - | SFT í•™ìŠµ (SingleFT-Movies) |
| **Set B** | `setB/by_model/singleft_music.jsonl` | 3,000 | - | SFT í•™ìŠµ (SingleFT-Music) |
| **Set B** | `setB/val.jsonl` | 12,000 | 146MB | DPO/GRPO (ì¶”í›„) |
| **Set B** | `setB/test.jsonl` | 30,000 | 362MB | ì‹¤í—˜ ê²°ê³¼ í‰ê°€ |

### 2.3 Model-Data Mapping

| Fine-tuning Model | Target Domain | User Types | Samples | Set A Path | Set B Path |
|-------------------|---------------|------------|---------|------------|------------|
| **DualFT-Movies** | Movies & TV | overlapping_books_movies (3K) + cold_start_*_movies (9K) | **12,000** | `setA/by_model/dualft_movies.jsonl` | `setB/by_model/dualft_movies.jsonl` |
| **DualFT-Music** | Music | overlapping_books_music (3K) + cold_start_*_music (9K) | **12,000** | `setA/by_model/dualft_music.jsonl` | `setB/by_model/dualft_music.jsonl` |
| **SingleFT-Movies** | Movies & TV | source_only_movies (3K) | **3,000** | `setA/by_model/singleft_movies.jsonl` | `setB/by_model/singleft_movies.jsonl` |
| **SingleFT-Music** | Music | source_only_music (3K) | **3,000** | `setA/by_model/singleft_music.jsonl` | `setB/by_model/singleft_music.jsonl` |

### 2.4 Data Usage by Training Stage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        KitREC Training Pipeline                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Stage 1: SFT (Supervised Fine-Tuning)                                  â”‚
â”‚  â”œâ”€â”€ Data: setA/by_model/*.jsonl or setB/by_model/*.jsonl               â”‚
â”‚  â”œâ”€â”€ Format: instruction + output (with <think> reasoning)              â”‚
â”‚  â””â”€â”€ Purpose: ê¸°ë³¸ ì¶”ì²œ ëŠ¥ë ¥ í•™ìŠµ                                        â”‚
â”‚                                                                         â”‚
â”‚  Stage 2: DPO/GRPO (Preference Optimization) - ì¶”í›„ ì§„í–‰                 â”‚
â”‚  â”œâ”€â”€ Data: setA/val.jsonl or setB/val.jsonl                             â”‚
â”‚  â”œâ”€â”€ Format: instruction + input + ground_truth (output ì—†ìŒ)           â”‚
â”‚  â””â”€â”€ Purpose: ì„ í˜¸ë„ ìµœì í™”, ë­í‚¹ í’ˆì§ˆ í–¥ìƒ                               â”‚
â”‚                                                                         â”‚
â”‚  Stage 3: Evaluation (ì‹¤í—˜ ê²°ê³¼)                                         â”‚
â”‚  â”œâ”€â”€ Data: setA/test.jsonl or setB/test.jsonl                           â”‚
â”‚  â”œâ”€â”€ Format: instruction + input + ground_truth (output ì—†ìŒ)           â”‚
â”‚  â””â”€â”€ Purpose: Hit@K, MRR, NDCG@10 ë“± ìµœì¢… ì„±ëŠ¥ í‰ê°€                      â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.5 User Type â†’ Model Mapping Detail

```
User Type Distribution (30,000 users total)
â”‚
â”œâ”€â”€ Target: Movies & TV (15,000 users)
â”‚   â”‚
â”‚   â”œâ”€â”€ DualFT-Movies (12,000 users) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   â”‚   â”œâ”€â”€ overlapping_books_movies    3,000   (Warm users) â”‚
â”‚   â”‚   â”œâ”€â”€ cold_start_2core_movies     3,000   (Cold-start) â”‚
â”‚   â”‚   â”œâ”€â”€ cold_start_3core_movies     3,000   (Cold-start) â”‚
â”‚   â”‚   â””â”€â”€ cold_start_4core_movies     3,000   (Cold-start) â”‚
â”‚   â”‚                                                         â”‚
â”‚   â””â”€â”€ SingleFT-Movies (3,000 users) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       â””â”€â”€ source_only_movies          3,000   (Extreme CS)  â”‚
â”‚                                                             â”‚
â””â”€â”€ Target: Music (15,000 users)                              â”‚
    â”‚                                                         â”‚
    â”œâ”€â”€ DualFT-Music (12,000 users) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚   â”œâ”€â”€ overlapping_books_music     3,000   (Warm users) â”‚
    â”‚   â”œâ”€â”€ cold_start_2core_music      3,000   (Cold-start) â”‚
    â”‚   â”œâ”€â”€ cold_start_3core_music      3,000   (Cold-start) â”‚
    â”‚   â””â”€â”€ cold_start_4core_music      3,000   (Cold-start) â”‚
    â”‚                                                         â”‚
    â””â”€â”€ SingleFT-Music (3,000 users) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€ source_only_music           3,000   (Extreme CS)
```

### 2.6 Fine-tuning Working Directory

```
./finetuning/                                  # Fine-tuning ì‘ì—… í´ë”
â”œâ”€â”€ PRD_FINETUNING.md                          # ë³¸ ë¬¸ì„œ
â”œâ”€â”€ finetuning_detail_task.md                  # Task tracking
â”œâ”€â”€ CLAUDE.md                                  # Claude Code guidance
â”œâ”€â”€ configs/                                   # í•™ìŠµ ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ base_config.yaml
â”‚   â”œâ”€â”€ dualft_movies.yaml
â”‚   â”œâ”€â”€ dualft_music.yaml
â”‚   â”œâ”€â”€ singleft_movies.yaml
â”‚   â””â”€â”€ singleft_music.yaml
â”œâ”€â”€ docs/                                      # ğŸ“ Documentation (NEW)
â”‚   â”œâ”€â”€ HYPERPARAMETER_TUNING_GUIDE.md         # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê°€ì´ë“œ
â”‚   â””â”€â”€ RUNPOD_TRAINING_GUIDE.md               # RunPod í•™ìŠµ ì‹¤í–‰ ê°€ì´ë“œ
â”œâ”€â”€ scripts/                                   # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ train.py                               # Training (with monitoring)
â”‚   â”œâ”€â”€ evaluate.py                            # Evaluation (robust parsing)
â”‚   â”œâ”€â”€ upload_to_hub.py                       # Training data upload
â”‚   â”œâ”€â”€ upload_val_to_hub.py                   # Validation data upload
â”‚   â”œâ”€â”€ upload_test_to_hub.py                  # Test data upload
â”‚   â””â”€â”€ upload_model_to_hub.py                 # Trained model upload
â”œâ”€â”€ src/                                       # Source utilities
â”‚   â”œâ”€â”€ data_utils.py                          # Data loading, tokenization
â”‚   â”œâ”€â”€ model_utils.py                         # QLoRA model setup
â”‚   â””â”€â”€ metrics.py                             # Evaluation metrics
â”œâ”€â”€ results/                                   # ì²´í¬í¬ì¸íŠ¸ ë° ê²°ê³¼
â”‚   â”œâ”€â”€ dualft_movies/
â”‚   â”‚   â”œâ”€â”€ setA/                              # Set Aë¡œ í•™ìŠµí•œ ëª¨ë¸
â”‚   â”‚   â””â”€â”€ setB/                              # Set Bë¡œ í•™ìŠµí•œ ëª¨ë¸
â”‚   â”œâ”€â”€ dualft_music/
â”‚   â”‚   â”œâ”€â”€ setA/
â”‚   â”‚   â””â”€â”€ setB/
â”‚   â”œâ”€â”€ singleft_movies/
â”‚   â”‚   â”œâ”€â”€ setA/
â”‚   â”‚   â””â”€â”€ setB/
â”‚   â””â”€â”€ singleft_music/
â”‚       â”œâ”€â”€ setA/
â”‚       â””â”€â”€ setB/
â””â”€â”€ logs/                                      # í•™ìŠµ ë¡œê·¸ (WandB + local)
```

### 2.7 Data Format

**Training Data (train.jsonl)**
```json
{
  "instruction": "[Student Prompt - GT ë¯¸í¬í•¨]",
  "input": "",
  "output": "<think>\n[Teacherê°€ ìƒì„±í•œ GT ê¸°ë°˜ reasoning]\n</think>\n```json\n{GT item JSON}\n```",
  "metadata": {
    "user_id": "string",
    "user_type": "string",
    "user_category": "overlapping | source_only | cold_start",
    "target_domain": "Movies & TV | Music",
    "source_domain": "Books",
    "target_core": "integer",
    "books_core": "integer",
    "candidate_set": "A | B",
    "gt_item_id": "string",
    "thinking_length": "integer",
    "confidence_score": "float",
    "generation_time_sec": "float"
  }
}
```

**Validation/Test Data (val.jsonl, test.jsonl)**
```json
{
  "instruction": "[System Prompt]",
  "input": "[User Prompt with candidates]",
  "output": "",
  "ground_truth": "[{\"item_id\": \"xxx\", \"title\": \"...\", ...}]",
  "metadata": { ... }
}
```

---

## 3. User Type Distribution

### 3.1 10 User Types (30,000 Users Total)

| User Type | Count | Target Domain | Training Model |
|-----------|-------|---------------|----------------|
| overlapping_books_movies | 3,000 | Movies & TV | DualFT-Movies |
| overlapping_books_music | 3,000 | Music | DualFT-Music |
| source_only_movies | 3,000 | Movies & TV | SingleFT-Movies |
| source_only_music | 3,000 | Music | SingleFT-Music |
| cold_start_2core_movies | 3,000 | Movies & TV | DualFT-Movies |
| cold_start_2core_music | 3,000 | Music | DualFT-Music |
| cold_start_3core_movies | 3,000 | Movies & TV | DualFT-Movies |
| cold_start_3core_music | 3,000 | Music | DualFT-Music |
| cold_start_4core_movies | 3,000 | Movies & TV | DualFT-Movies |
| cold_start_4core_music | 3,000 | Music | DualFT-Music |

### 3.2 4 Fine-tuning Models

| Model | Training Users | Sample Count | Purpose |
|-------|----------------|--------------|---------|
| **DualFT-Movies** | overlapping_books_movies + cold_start_*_movies | 12,000 | Movies & TV ì¶”ì²œ (Warm + Cold) |
| **DualFT-Music** | overlapping_books_music + cold_start_*_music | 12,000 | Music ì¶”ì²œ (Warm + Cold) |
| **SingleFT-Movies** | source_only_movies | 3,000 | Movies & TV ê·¹í•œ Cold-start |
| **SingleFT-Music** | source_only_music | 3,000 | Music ê·¹í•œ Cold-start |

---

## 4. Train/Val Split Strategy

### 4.1 Stratified Split by User Type (9:1)

ëª¨ë“  10ê°œ user_typeì—ì„œ ë™ì¼í•œ ë¹„ìœ¨ë¡œ Train/Valì„ ë¶„í• í•˜ì—¬ **ì •í™•í•œ train lossì™€ val loss** ì¸¡ì •ì„ ë³´ì¥í•©ë‹ˆë‹¤.

```python
# Stratified split implementation
SPLIT_CONFIG = {
    "method": "stratified_by_user_type",
    "train_ratio": 0.9,
    "val_ratio": 0.1,
    "stratify_by": ["user_type"],
    "seed": 42,
    "ensure_same_users_across_sets": True  # Set Aì™€ Set B ë™ì¼ ì‚¬ìš©ì ë¶„í• 
}
```

### 4.2 Split Counts per Model

**DualFT Models (12,000 samples each)**
| User Type | Total | Train (90%) | Val (10%) |
|-----------|-------|-------------|-----------|
| overlapping_books_movies | 3,000 | 2,700 | 300 |
| cold_start_2core_movies | 3,000 | 2,700 | 300 |
| cold_start_3core_movies | 3,000 | 2,700 | 300 |
| cold_start_4core_movies | 3,000 | 2,700 | 300 |
| **DualFT-Movies Total** | **12,000** | **10,800** | **1,200** |

| User Type | Total | Train (90%) | Val (10%) |
|-----------|-------|-------------|-----------|
| overlapping_books_music | 3,000 | 2,700 | 300 |
| cold_start_2core_music | 3,000 | 2,700 | 300 |
| cold_start_3core_music | 3,000 | 2,700 | 300 |
| cold_start_4core_music | 3,000 | 2,700 | 300 |
| **DualFT-Music Total** | **12,000** | **10,800** | **1,200** |

**SingleFT Models (3,000 samples each)**
| User Type | Total | Train (90%) | Val (10%) |
|-----------|-------|-------------|-----------|
| source_only_movies | 3,000 | 2,700 | 300 |
| **SingleFT-Movies Total** | **3,000** | **2,700** | **300** |

| User Type | Total | Train (90%) | Val (10%) |
|-----------|-------|-------------|-----------|
| source_only_music | 3,000 | 2,700 | 300 |
| **SingleFT-Music Total** | **3,000** | **2,700** | **300** |

### 4.3 Set A/B Consistency

**ì¤‘ìš”**: Set Aì™€ Set BëŠ” **ë™ì¼í•œ ì‚¬ìš©ì ë¶„í• **ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
# ë™ì¼í•œ user_idë¥¼ Train/Valì— í• ë‹¹
# Set A train users == Set B train users
# Set A val users == Set B val users

def create_consistent_split(users_df, val_ratio=0.1, seed=42):
    """User-level splitì„ ë¨¼ì € ìˆ˜í–‰í•˜ê³ , Set A/B ëª¨ë‘ì— ì ìš©"""
    from sklearn.model_selection import StratifiedShuffleSplit

    splitter = StratifiedShuffleSplit(
        n_splits=1,
        test_size=val_ratio,
        random_state=seed
    )

    train_idx, val_idx = next(splitter.split(
        users_df,
        users_df['user_type']
    ))

    train_users = set(users_df.iloc[train_idx]['user_id'])
    val_users = set(users_df.iloc[val_idx]['user_id'])

    return train_users, val_users
```

---

## 5. PEFT QLoRA Configuration

### 5.1 Model Configuration

```python
from transformers import BitsAndBytesConfig
from peft import LoraConfig, TaskType
import torch

# =============================================================================
# BASE MODEL: Qwen3-14B
# =============================================================================
MODEL_NAME = "Qwen/Qwen3-14B"

# =============================================================================
# 4-bit QUANTIZATION (QLoRA)
# =============================================================================
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",           # Normal Float 4-bit (optimal for LLMs)
    bnb_4bit_compute_dtype=torch.bfloat16,  # A100/H100 native support
    bnb_4bit_use_double_quant=True,       # ~1GB VRAM ì ˆì•½
)

# =============================================================================
# LoRA CONFIGURATION - DualFT (12K samples, cross-domain transfer)
# =============================================================================
lora_config_dualft = LoraConfig(
    # Rank: 32 (Expert-Verified: increased for better cross-domain reasoning)
    r=32,

    # Alpha: 64 (Maintain alpha/r = 2 ratio)
    lora_alpha=64,

    # Target Modules: Qwen3 Attention + MLP
    target_modules=[
        "q_proj",      # Query projection
        "k_proj",      # Key projection
        "v_proj",      # Value projection
        "o_proj",      # Output projection
        "gate_proj",   # MLP gating (SwiGLU)
        "up_proj",     # MLP up projection
        "down_proj",   # MLP down projection
    ],

    # Dropout: 0.08 (Expert-Verified: explicit for DualFT regularization)
    lora_dropout=0.08,
    bias="none",
    task_type=TaskType.CAUSAL_LM,
)

# =============================================================================
# LoRA CONFIGURATION - SingleFT (3K samples, overfitting prevention)
# =============================================================================
lora_config_singleft = LoraConfig(
    # Rank: 24 (Expert-Verified: slightly less than DualFT)
    r=24,

    # Alpha: 48 (Maintain alpha/r = 2 ratio)
    lora_alpha=48,

    # Target Modules: Qwen3 Attention + MLP
    target_modules=[
        "q_proj",      # Query projection
        "k_proj",      # Key projection
        "v_proj",      # Value projection
        "o_proj",      # Output projection
        "gate_proj",   # MLP gating (SwiGLU)
        "up_proj",     # MLP up projection
        "down_proj",   # MLP down projection
    ],

    # Dropout: 0.15 (Expert-Verified: aggressive overfitting prevention)
    lora_dropout=0.15,
    bias="none",
    task_type=TaskType.CAUSAL_LM,
)
```

### 5.2 Training Arguments (DualFT - 12K samples)

```python
from transformers import TrainingArguments

# =============================================================================
# TRAINING ARGUMENTS - DualFT Models (12,000 samples)
# =============================================================================
training_args_dualft = TrainingArguments(
    output_dir="./results/dualft_movies",  # ë˜ëŠ” dualft_music

    # ----- Batch Size -----
    # Effective batch = 4 Ã— 8 = 32
    per_device_train_batch_size=4,
    per_device_eval_batch_size=8,
    gradient_accumulation_steps=8,

    # ----- Learning Rate -----
    # 2e-4: QLoRA í‘œì¤€ (frozen base weightsë¡œ ë†’ì€ LR ê°€ëŠ¥)
    learning_rate=2e-4,

    # ----- Epochs -----
    # 3 epochs: 12K Ã— 3 = 36K effective samples
    # Early stoppingìœ¼ë¡œ ê³¼ì í•© ë°©ì§€
    num_train_epochs=3,

    # ----- Evaluation Strategy -----
    # 200 stepsë§ˆë‹¤ ê²€ì¦ (epochë‹¹ ~5-6íšŒ)
    eval_strategy="steps",
    eval_steps=200,

    # ----- Save Strategy -----
    save_strategy="steps",
    save_steps=200,
    save_total_limit=3,  # ìµœê·¼ 3ê°œ ì²´í¬í¬ì¸íŠ¸ë§Œ ìœ ì§€

    # ----- Best Model Selection -----
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    greater_is_better=False,

    # ----- Learning Rate Schedule -----
    warmup_ratio=0.05,           # 5% warmup
    lr_scheduler_type="cosine",  # Cosine annealing

    # ----- Precision -----
    bf16=True,                   # A100/H100 native BF16
    fp16=False,

    # ----- Memory Optimization -----
    gradient_checkpointing=True,
    gradient_checkpointing_kwargs={"use_reentrant": False},

    # ----- Regularization (Expert-Verified: Cross-Domain Overfitting Prevention) -----
    weight_decay=0.02,           # Cross-domain overfitting prevention
    label_smoothing_factor=0.05, # Confidence calibration for cross-domain

    # ----- NEFTune (Instruction Tuning ì„±ëŠ¥ í–¥ìƒ) -----
    # Expert-Verified: DualFT 5.0 (standard), SingleFT 3.0 (smaller dataset)
    neftune_noise_alpha=5.0,  # DualFT: 5.0 explicit

    # ----- Optimizer -----
    optim="adamw_torch_fused",   # A100/H100 ìµœì í™”
    max_grad_norm=1.0,           # Gradient clipping

    # ----- Data Loading -----
    dataloader_num_workers=4,
    dataloader_pin_memory=True,
    group_by_length=True,        # ìœ ì‚¬ ê¸¸ì´ ìƒ˜í”Œ ê·¸ë£¹í™”

    # ----- Logging -----
    logging_dir="./logs",
    logging_strategy="steps",
    logging_steps=50,
    report_to=["wandb"],  # TensorBoard â†’ WandB (with error handling in train.py)

    # ----- Reproducibility -----
    seed=42,
    data_seed=42,
)
```

### 5.3 Training Arguments (SingleFT - 3K samples)

```python
# =============================================================================
# TRAINING ARGUMENTS - SingleFT Models (3,000 samples)
# =============================================================================
# SingleFTëŠ” Base Model(Qwen3-14B)ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµ (DualFT ì²´í¬í¬ì¸íŠ¸ ë¯¸ì‚¬ìš©)

training_args_singleft = TrainingArguments(
    output_dir="./results/singleft_movies",  # ë˜ëŠ” singleft_music

    # ----- Batch Size -----
    # ì‘ì€ ë°ì´í„°ì…‹ì´ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° ì¶•ì†Œ
    per_device_train_batch_size=2,
    per_device_eval_batch_size=4,
    gradient_accumulation_steps=16,  # Effective batch = 32 ìœ ì§€

    # ----- Learning Rate -----
    # Expert-Verified: ë” ë‚®ì€ LRë¡œ ê³¼ì í•© ë°©ì§€
    learning_rate=6e-5,  # 1e-4 â†’ 6e-5 (aggressive overfitting prevention)

    # ----- Epochs -----
    # 6 epochs: 3K Ã— 6 = 18K effective samples
    # DualFT (36K)ì™€ ìœ ì‚¬í•œ ìˆ˜ì¤€ì˜ í•™ìŠµëŸ‰
    num_train_epochs=6,

    # ----- Evaluation Strategy -----
    # ë” ìì£¼ ê²€ì¦ (ê³¼ì í•© ëª¨ë‹ˆí„°ë§) - Expert-Verified: 100 â†’ 50
    eval_strategy="steps",
    eval_steps=50,  # 100 â†’ 50 for faster early stopping detection

    # ----- Save Strategy -----
    save_strategy="steps",
    save_steps=100,
    save_total_limit=3,

    # ----- Best Model Selection -----
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    greater_is_better=False,

    # ----- Learning Rate Schedule -----
    warmup_ratio=0.1,            # 10% warmup (ì‘ì€ ë°ì´í„°ì…‹)
    lr_scheduler_type="cosine",

    # ----- Regularization (Expert-Verified: Aggressive Overfitting Prevention) -----
    weight_decay=0.05,           # 0.01 â†’ 0.05 (stronger L2 regularization)
    label_smoothing_factor=0.1,  # Prevent overconfidence, improve generalization

    # ----- Precision & Memory -----
    bf16=True,
    gradient_checkpointing=True,
    gradient_checkpointing_kwargs={"use_reentrant": False},

    # ----- NEFTune -----
    # Expert-Verified: SingleFT uses 3.0 (smaller dataset needs less noise)
    neftune_noise_alpha=3.0,  # 5.0 â†’ 3.0 for SingleFT

    # ----- Optimizer -----
    optim="adamw_torch_fused",
    max_grad_norm=1.0,

    # ----- Data Loading -----
    dataloader_num_workers=4,
    dataloader_pin_memory=True,
    group_by_length=True,

    # ----- Logging -----
    logging_dir="./logs",
    logging_strategy="steps",
    logging_steps=25,
    report_to=["wandb"],  # TensorBoard â†’ WandB (with error handling in train.py)

    # ----- Reproducibility -----
    seed=42,
    data_seed=42,
)
```

### 5.4 Early Stopping Configuration

```python
from transformers import EarlyStoppingCallback

early_stopping = EarlyStoppingCallback(
    early_stopping_patience=3,      # 3íšŒ ì—°ì† ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨
    early_stopping_threshold=0.001,  # ìµœì†Œ 0.1% ê°œì„  í•„ìš”
)
```

---

## 6. Training Pipeline

### 6.1 Training Hierarchy (Independent Training)

```
Training Pipeline (All models start from Base Model):

                    Qwen3-14B (Base Model)
                           â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼               â–¼               â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  DualFT   â”‚   â”‚  DualFT   â”‚   â”‚ SingleFT  â”‚
     â”‚  Movies   â”‚   â”‚  Music    â”‚   â”‚  Movies   â”‚
     â”‚   12K     â”‚   â”‚   12K     â”‚   â”‚    3K     â”‚
     â”‚ 3 epochs  â”‚   â”‚ 3 epochs  â”‚   â”‚ 6 epochs  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                     â”Œâ”€â”€â”€â”€â”€â”˜
                                     â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚ SingleFT  â”‚
                               â”‚  Music    â”‚
                               â”‚    3K     â”‚
                               â”‚ 6 epochs  â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Note: SingleFT ëª¨ë¸ì€ DualFT ì²´í¬í¬ì¸íŠ¸ê°€ ì•„ë‹Œ Base Modelì—ì„œ ë…ë¦½ í•™ìŠµ
```

### 6.2 Training Order

1. **DualFT-Movies** (Set A) â†’ **DualFT-Movies** (Set B)
2. **DualFT-Music** (Set A) â†’ **DualFT-Music** (Set B)
3. **SingleFT-Movies** (Set A) â†’ **SingleFT-Movies** (Set B)
4. **SingleFT-Music** (Set A) â†’ **SingleFT-Music** (Set B)

### 6.3 Estimated Training Time (A100 80GB)

| Model | Samples | Epochs | Est. Time |
|-------|---------|--------|-----------|
| DualFT-Movies (Set A) | 10,800 train | 3 | ~2-3 hours |
| DualFT-Movies (Set B) | 10,800 train | 3 | ~2-3 hours |
| DualFT-Music (Set A) | 10,800 train | 3 | ~2-3 hours |
| DualFT-Music (Set B) | 10,800 train | 3 | ~2-3 hours |
| SingleFT-Movies (Set A) | 2,700 train | 6 | ~1.5-2 hours |
| SingleFT-Movies (Set B) | 2,700 train | 6 | ~1.5-2 hours |
| SingleFT-Music (Set A) | 2,700 train | 6 | ~1.5-2 hours |
| SingleFT-Music (Set B) | 2,700 train | 6 | ~1.5-2 hours |
| **Total** | - | - | **~16-20 hours** |

---

## 7. VRAM Usage Estimation

### 7.1 Memory Breakdown (A100/H100 80GB)

```
=============================================================================
VRAM BREAKDOWN (Qwen3-14B QLoRA)
=============================================================================

Component                          | VRAM Usage
-----------------------------------|-------------
Qwen3-14B (4-bit quantized)        | ~8 GB
LoRA adapters (r=16, all modules)  | ~50 MB
Optimizer states (AdamW fused)     | ~100 MB
Gradients (with checkpointing)     | ~4 GB
Activations (batch=4, seq=8192)    | ~35 GB
KV Cache (during eval)             | ~2 GB
CUDA kernels + overhead            | ~3 GB
-----------------------------------|-------------
TOTAL (Training)                   | ~52 GB
TOTAL (Inference/Eval)             | ~15 GB

Headroom on 80GB                   | ~28 GB (SAFE)
```

### 7.2 Memory Optimization (OOM ë°œìƒ ì‹œ)

```python
# Option 1: Batch size ì¶•ì†Œ
per_device_train_batch_size=2  # 4 â†’ 2
gradient_accumulation_steps=16  # 8 â†’ 16 (effective batch ìœ ì§€)

# Option 2: Sequence length ì œí•œ (ì°¸ê³ : ê¸°ë³¸ê°’ì€ 8192)
max_length=4096  # 8192 â†’ 4096 (if OOM)

# Option 3: 8-bit Optimizer
optim="adamw_8bit"  # bitsandbytes 8-bit optimizer
```

---

## 8. Evaluation Metrics

### 8.1 Primary Metrics (Mandatory)

| Metric | Formula | Purpose |
|--------|---------|---------|
| **eval_loss** | Cross-entropy loss | í•™ìŠµ ì§„í–‰ ëª¨ë‹ˆí„°ë§ |
| **Hit@1** | 1 if GT in top-1 | ì •í™•ë„ (Exact match) |
| **Hit@5** | 1 if GT in top-5 | Top-K ì„±ëŠ¥ |
| **MRR** | 1/rank of GT | ë­í‚¹ í’ˆì§ˆ |
| **NDCG@10** | DCG@10 / IDCG@10 | Position-weighted ì„±ëŠ¥ |

### 8.2 Secondary Metrics

| Metric | Purpose |
|--------|---------|
| **Confidence MAE** | ì˜ˆì¸¡ ì‹ ë¢°ë„ ë³´ì • |
| **Thinking Length** | ì¶”ë¡  ê¹Šì´ |
| **Cross-Domain Refs** | Sourceâ†’Target ì°¸ì¡° íšŸìˆ˜ |

### 8.3 Stratified Evaluation

ëª¨ë“  í‰ê°€ëŠ” ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ì¸µí™”(stratified) ë¶„ì„:

```python
STRATIFIED_EVALUATION = {
    "by_user_type": [
        "overlapping", "source_only",
        "cold_start_2core", "cold_start_3core", "cold_start_4core"
    ],
    "by_target_domain": ["Movies & TV", "Music"],
    "by_target_core": [1, 2, 3, 4, "5+", "10+"],
    "by_candidate_set": ["Set A (Hybrid)", "Set B (Random)"]
}
```

---

## 9. Hugging Face Integration

### 9.1 Data Upload to Hub (Per-Model Repositories)

**ë³€ê²½ ì‚¬í•­ (2025-11-30):**
- ëª¨ë¸ë³„ ë³„ë„ ë¦¬í¬ì§€í† ë¦¬ë¡œ ì—…ë¡œë“œ (8ê°œ ë¦¬í¬ì§€í† ë¦¬)
- test ë°ì´í„° ì œì™¸ (ë¡œì»¬ í‰ê°€)
- ê° ë¦¬í¬ì§€í† ë¦¬ì— README.md (ë°ì´í„°ì…‹ ì¹´ë“œ) í¬í•¨

```bash
# Upload single model dataset with README.md
python scripts/upload_to_hub.py --model_type dualft_movies --set A

# Upload all datasets for Set A
python scripts/upload_to_hub.py --set A --all

# Upload all datasets (both sets, 8 repositories)
python scripts/upload_to_hub.py --all
```

**Dataset Repositories (8ê°œ):**
```
Younggooo/kitrec-dualft-movies-seta     # 12,000 samples
Younggooo/kitrec-dualft-movies-setb     # 12,000 samples
Younggooo/kitrec-dualft-music-seta      # 12,000 samples
Younggooo/kitrec-dualft-music-setb      # 12,000 samples
Younggooo/kitrec-singleft-movies-seta   # 3,000 samples
Younggooo/kitrec-singleft-movies-setb   # 3,000 samples
Younggooo/kitrec-singleft-music-seta    # 3,000 samples
Younggooo/kitrec-singleft-music-setb    # 3,000 samples
```

### 9.2 Model Upload to Hub

```python
from peft import PeftModel

# After training
def save_and_upload_model(model, tokenizer, output_dir, hub_name):
    # Save locally
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)

    # Push to Hub
    model.push_to_hub(
        hub_name,
        private=True,
        token="hf_xxx"
    )
    tokenizer.push_to_hub(
        hub_name,
        private=True,
        token="hf_xxx"
    )

# Usage
save_and_upload_model(
    model=trainer.model,
    tokenizer=tokenizer,
    output_dir="./results/dualft_movies/best",
    hub_name="your-username/kitrec-dualft-movies-setA"
)
```

### 9.3 Hub Repository Structure (Updated 2025-11-30)

```
Hugging Face Hub:
â”œâ”€â”€ Training Datasets (ëª¨ë¸ë³„ ë³„ë„ ë¦¬í¬ì§€í† ë¦¬)
â”‚   â”œâ”€â”€ kitrec-dualft_movies-seta    # DualFT Movies Set A (12K)
â”‚   â”œâ”€â”€ kitrec-dualft_movies-setb    # DualFT Movies Set B (12K)
â”‚   â”œâ”€â”€ kitrec-dualft_music-seta     # DualFT Music Set A (12K)
â”‚   â”œâ”€â”€ kitrec-dualft_music-setb     # DualFT Music Set B (12K)
â”‚   â”œâ”€â”€ kitrec-singleft_movies-seta  # SingleFT Movies Set A (3K)
â”‚   â”œâ”€â”€ kitrec-singleft_movies-setb  # SingleFT Movies Set B (3K)
â”‚   â”œâ”€â”€ kitrec-singleft_music-seta   # SingleFT Music Set A (3K)
â”‚   â””â”€â”€ kitrec-singleft_music-setb   # SingleFT Music Set B (3K)
â”‚
â”œâ”€â”€ Validation Datasets (Setë³„)
â”‚   â”œâ”€â”€ kitrec-val-seta              # Validation Set A (12K)
â”‚   â””â”€â”€ kitrec-val-setb              # Validation Set B (12K)
â”‚
â”œâ”€â”€ Test Datasets (Setë³„)
â”‚   â”œâ”€â”€ kitrec-test-seta             # Test Set A (30K)
â”‚   â””â”€â”€ kitrec-test-setb             # Test Set B (30K)
â”‚
â””â”€â”€ Models (í•™ìŠµ ì™„ë£Œ í›„ ì—…ë¡œë“œ)
    â”œâ”€â”€ kitrec-dualft-movies-setA-model
    â”œâ”€â”€ kitrec-dualft-movies-setB-model
    â”œâ”€â”€ kitrec-dualft-music-setA-model
    â”œâ”€â”€ kitrec-dualft-music-setB-model
    â”œâ”€â”€ kitrec-singleft-movies-setA-model
    â”œâ”€â”€ kitrec-singleft-movies-setB-model
    â”œâ”€â”€ kitrec-singleft-music-setA-model
    â””â”€â”€ kitrec-singleft-music-setB-model
```

---

## 10. Implementation Checklist

### 10.1 Pre-Training

- [ ] RunPod A100/H100 80GB ì¸ìŠ¤í„´ìŠ¤ ì¤€ë¹„
- [x] Hugging Face Hub ë°ì´í„°ì…‹ ì—…ë¡œë“œ (12 repositories - train/val/test)
- [ ] Flash Attention 2 ì„¤ì¹˜: `pip install flash-attn --no-build-isolation`
- [ ] bitsandbytes ì„¤ì¹˜: `pip install bitsandbytes`
- [ ] PEFT ì„¤ì¹˜: `pip install peft`
- [ ] Train/Val stratified split ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] ì„¤ì • íŒŒì¼ (YAML) ì‘ì„±

### 10.2 Training

- [ ] DualFT-Movies (Set A) í•™ìŠµ
- [ ] DualFT-Movies (Set B) í•™ìŠµ
- [ ] DualFT-Music (Set A) í•™ìŠµ
- [ ] DualFT-Music (Set B) í•™ìŠµ
- [ ] SingleFT-Movies (Set A) í•™ìŠµ (Base Model ë…ë¦½ í•™ìŠµ)
- [ ] SingleFT-Movies (Set B) í•™ìŠµ (Base Model ë…ë¦½ í•™ìŠµ)
- [ ] SingleFT-Music (Set A) í•™ìŠµ (Base Model ë…ë¦½ í•™ìŠµ)
- [ ] SingleFT-Music (Set B) í•™ìŠµ (Base Model ë…ë¦½ í•™ìŠµ)

### 10.3 Evaluation

- [ ] Val set eval_loss ìˆ˜ë ´ í™•ì¸
- [ ] Test set Hit@1, Hit@5, MRR, NDCG@10 ê³„ì‚°
- [ ] User typeë³„ stratified ì„±ëŠ¥ ë¶„ì„
- [ ] Set A vs Set B ë¹„êµ ë¶„ì„

### 10.4 Post-Training

- [ ] Best ì²´í¬í¬ì¸íŠ¸ Hugging Face Hub ì—…ë¡œë“œ
- [ ] Training loss/val loss ê·¸ë˜í”„ ì €ì¥
- [ ] ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì‘ì„±

---

## 11. Appendix

### A. Complete Training Script

```python
#!/usr/bin/env python3
"""
KitREC Fine-tuning Script
PEFT QLoRA on Qwen3-14B for Cross-Domain Recommendation
"""

import torch
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    DataCollatorForSeq2Seq,
    EarlyStoppingCallback,
    BitsAndBytesConfig,
)
from peft import LoraConfig, TaskType, get_peft_model, prepare_model_for_kbit_training
from datasets import load_dataset
import argparse

def main(args):
    # Model configuration
    MODEL_NAME = "Qwen/Qwen3-14B"

    # BitsAndBytes 4-bit config
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.bfloat16,
        bnb_4bit_use_double_quant=True,
    )

    # LoRA config
    lora_config = LoraConfig(
        r=16,
        lora_alpha=32,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                       "gate_proj", "up_proj", "down_proj"],
        lora_dropout=0.05,
        bias="none",
        task_type=TaskType.CAUSAL_LM,
    )

    # Load tokenizer
    print("Loading tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(
        MODEL_NAME,
        trust_remote_code=True,
        padding_side="left",
    )
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    # Load model with quantization
    print("Loading model...")
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_NAME,
        quantization_config=bnb_config,
        attn_implementation="flash_attention_2",
        device_map="auto",
        trust_remote_code=True,
        torch_dtype=torch.bfloat16,
    )

    # Prepare for k-bit training
    model = prepare_model_for_kbit_training(
        model,
        use_gradient_checkpointing=True,
        gradient_checkpointing_kwargs={"use_reentrant": False}
    )

    # Apply LoRA
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()

    # Load dataset from Hub
    print("Loading dataset...")
    dataset = load_dataset(f"your-username/kitrec-instruction-{args.candidate_set.lower()}")

    # Filter by model type
    if args.model_type.startswith("dualft"):
        domain = "Movies & TV" if "movies" in args.model_type else "Music"
        categories = ["overlapping", "cold_start"]
        dataset = dataset.filter(
            lambda x: x["metadata"]["target_domain"] == domain and
                     x["metadata"]["user_category"] in categories
        )
    else:  # singleft
        domain = "Movies & TV" if "movies" in args.model_type else "Music"
        dataset = dataset.filter(
            lambda x: x["metadata"]["target_domain"] == domain and
                     x["metadata"]["user_category"] == "source_only"
        )

    # Tokenization
    def tokenize_function(examples):
        texts = []
        for instruction, output in zip(examples["instruction"], examples["output"]):
            text = f"<|im_start|>user\n{instruction}<|im_end|>\n<|im_start|>assistant\n{output}<|im_end|>"
            texts.append(text)

        tokenized = tokenizer(
            texts,
            truncation=True,
            max_length=8192,  # Expert-Verified: 4096â†’8192 (99.26% coverage)
            padding=False,
        )
        tokenized["labels"] = tokenized["input_ids"].copy()
        return tokenized

    train_dataset = dataset["train"].map(tokenize_function, batched=True)
    val_dataset = dataset["validation"].map(tokenize_function, batched=True)

    # Data collator
    data_collator = DataCollatorForSeq2Seq(
        tokenizer=tokenizer,
        model=model,
        padding="longest",
        max_length=8192,  # Expert-Verified: 4096â†’8192 (99.26% coverage)
        label_pad_token_id=-100,
    )

    # Training arguments
    is_singleft = args.model_type.startswith("singleft")
    training_args = TrainingArguments(
        output_dir=f"./results/{args.model_type}_{args.candidate_set}",
        per_device_train_batch_size=2 if is_singleft else 4,
        per_device_eval_batch_size=4 if is_singleft else 8,
        gradient_accumulation_steps=16 if is_singleft else 8,
        learning_rate=1e-4 if is_singleft else 2e-4,
        num_train_epochs=6 if is_singleft else 3,
        eval_strategy="steps",
        eval_steps=100 if is_singleft else 200,
        save_strategy="steps",
        save_steps=100 if is_singleft else 200,
        save_total_limit=3,
        load_best_model_at_end=True,
        metric_for_best_model="eval_loss",
        greater_is_better=False,
        warmup_ratio=0.1 if is_singleft else 0.05,
        lr_scheduler_type="cosine",
        bf16=True,
        gradient_checkpointing=True,
        gradient_checkpointing_kwargs={"use_reentrant": False},
        neftune_noise_alpha=5.0,
        optim="adamw_torch_fused",
        max_grad_norm=1.0,
        dataloader_num_workers=4,
        logging_steps=25 if is_singleft else 50,
        report_to=["tensorboard"],
        seed=42,
    )

    # Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        data_collator=data_collator,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],
    )

    # Train
    print("Starting training...")
    trainer.train()

    # Save best model
    print("Saving model...")
    trainer.save_model(f"./results/{args.model_type}_{args.candidate_set}/best")
    tokenizer.save_pretrained(f"./results/{args.model_type}_{args.candidate_set}/best")

    # Push to Hub
    if args.push_to_hub:
        print("Pushing to Hub...")
        trainer.model.push_to_hub(
            f"your-username/kitrec-{args.model_type}-{args.candidate_set.lower()}",
            private=True
        )

    print("Done!")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_type", type=str, required=True,
                       choices=["dualft_movies", "dualft_music",
                               "singleft_movies", "singleft_music"])
    parser.add_argument("--candidate_set", type=str, required=True,
                       choices=["setA", "setB"])
    parser.add_argument("--push_to_hub", action="store_true")
    args = parser.parse_args()
    main(args)
```

### B. Data Preparation Script

```python
#!/usr/bin/env python3
"""
Prepare KitREC data: Stratified Train/Val split by user_type
"""

import json
from collections import defaultdict
from sklearn.model_selection import StratifiedShuffleSplit
import random

def stratified_split(data, val_ratio=0.1, seed=42):
    """Stratified split by user_type"""
    random.seed(seed)

    # Group by user_type
    type_groups = defaultdict(list)
    for item in data:
        user_type = item["metadata"]["user_type"]
        type_groups[user_type].append(item)

    train_data, val_data = [], []

    for user_type, items in type_groups.items():
        random.shuffle(items)
        split_idx = int(len(items) * (1 - val_ratio))
        train_data.extend(items[:split_idx])
        val_data.extend(items[split_idx:])

        print(f"{user_type}: Train {split_idx}, Val {len(items) - split_idx}")

    return train_data, val_data

def main():
    for candidate_set in ["setA", "setB"]:
        print(f"\n=== Processing {candidate_set} ===")

        # Load full train data
        filepath = f"../data/instruction/{candidate_set}/train.jsonl"
        with open(filepath, 'r') as f:
            data = [json.loads(line) for line in f]

        print(f"Total samples: {len(data)}")

        # Stratified split
        train_data, val_data = stratified_split(data, val_ratio=0.1, seed=42)

        # Save
        train_out = f"../data/instruction/{candidate_set}/train_split.jsonl"
        val_out = f"../data/instruction/{candidate_set}/val_split.jsonl"

        with open(train_out, 'w') as f:
            for item in train_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')

        with open(val_out, 'w') as f:
            for item in val_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')

        print(f"Train: {len(train_data)} -> {train_out}")
        print(f"Val: {len(val_data)} -> {val_out}")

if __name__ == "__main__":
    main()
```

---

---

**END OF DOCUMENT**
