# KitREC RunPod í™˜ê²½ ì„¤ì • ê°€ì´ë“œ

**ìµœì¢… ì—…ë°ì´íŠ¸:** 2025-12-07
**ëª©ì :** KitREC ì‹¤í—˜ì„ ìœ„í•œ RunPod í™˜ê²½ êµ¬ì¶• ë° ì‹¤í–‰ ê°€ì´ë“œ

---

## ëª©ì°¨

1. [ì‚¬ì „ ì¤€ë¹„ (ë¡œì»¬)](#1-ì‚¬ì „-ì¤€ë¹„-ë¡œì»¬)
2. [RunPod ê³„ì • ë° ê²°ì œ ì„¤ì •](#2-runpod-ê³„ì •-ë°-ê²°ì œ-ì„¤ì •)
3. [Pod ìƒì„±](#3-pod-ìƒì„±)
4. [í™˜ê²½ ì„¤ì •](#4-í™˜ê²½-ì„¤ì •)
5. [í”„ë¡œì íŠ¸ ì—…ë¡œë“œ](#5-í”„ë¡œì íŠ¸-ì—…ë¡œë“œ)
6. [í™˜ê²½ ê²€ì¦](#6-í™˜ê²½-ê²€ì¦)
7. [ì‹¤í—˜ ì‹¤í–‰](#7-ì‹¤í—˜-ì‹¤í–‰)
8. [ë¬¸ì œ í•´ê²°](#8-ë¬¸ì œ-í•´ê²°)
9. [ë¹„ìš© ìµœì í™” íŒ](#9-ë¹„ìš©-ìµœì í™”-íŒ)

---

## 1. ì‚¬ì „ ì¤€ë¹„ (ë¡œì»¬)

### 1.1 í•„ìˆ˜ ì¤€ë¹„ë¬¼

| í•­ëª© | ì„¤ëª… | í™•ì¸ ë°©ë²• |
|------|------|----------|
| **HuggingFace Token** | Private ëª¨ë¸ ì ‘ê·¼ìš© | [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) |
| **RunPod ê³„ì •** | GPU ì„œë²„ ëŒ€ì—¬ | [runpod.io](https://runpod.io) |
| **ê²°ì œ ìˆ˜ë‹¨** | í¬ë ˆë”§ ì¹´ë“œ ë˜ëŠ” ì•”í˜¸í™”í | RunPod Billing |
| **í”„ë¡œì íŠ¸ ì½”ë“œ** | ë¡œì»¬ ê²€ì¦ ì™„ë£Œëœ ì½”ë“œ | `scripts/verify_local.py` ì‹¤í–‰ |

### 1.2 HuggingFace Token ë°œê¸‰

```bash
# 1. https://huggingface.co/settings/tokens ì ‘ì†
# 2. "New token" í´ë¦­
# 3. Name: "KitREC-RunPod"
# 4. Type: "Read" (ì½ê¸° ì „ìš©ì´ë©´ ì¶©ë¶„)
# 5. í† í° ë³µì‚¬ í›„ ì•ˆì „í•œ ê³³ì— ì €ì¥

# í† í° í˜•ì‹ ì˜ˆì‹œ
hf_aBcDeFgHiJkLmNoPqRsTuVwXyZ123456
```

### 1.3 ë¡œì»¬ ì½”ë“œ ê²€ì¦ (í•„ìˆ˜!)

```bash
# RunPod ë°°í¬ ì „ ë¡œì»¬ì—ì„œ ë°˜ë“œì‹œ ì‹¤í–‰
cd /path/to/Experimental_test
python scripts/verify_local.py

# ëª¨ë“  ì²´í¬ê°€ í†µê³¼í•´ì•¼ í•¨
# âœ… Python syntax check
# âœ… Import verification
# âœ… Baseline model instantiation
# âœ… Data loader test
```

---

## 2. RunPod ê³„ì • ë° ê²°ì œ ì„¤ì •

### 2.1 ê³„ì • ìƒì„±

1. [runpod.io](https://runpod.io) ì ‘ì†
2. "Sign Up" â†’ GitHub/Google ê³„ì •ìœ¼ë¡œ ê°€ì…
3. ì´ë©”ì¼ ì¸ì¦ ì™„ë£Œ

### 2.2 ê²°ì œ ì„¤ì •

```
Settings â†’ Billing â†’ Add Payment Method
- Credit Card (ê¶Œì¥)
- Crypto (Bitcoin, Ethereum ë“±)

ê¶Œì¥ ì´ˆê¸° ì¶©ì „: $50-100 (í…ŒìŠ¤íŠ¸ + ì´ˆê¸° ì‹¤í—˜ìš©)
```

### 2.3 ì˜ˆìƒ ë¹„ìš©

| GPU | ì‹œê°„ë‹¹ ë¹„ìš© | 24ì‹œê°„ ë¹„ìš© | ìš©ë„ |
|-----|-----------|------------|------|
| RTX 4090 (24GB) | $0.44 | $10.56 | í…ŒìŠ¤íŠ¸/ì†Œê·œëª¨ ì‹¤í—˜ |
| A100 40GB | $1.29 | $30.96 | ì¤‘ê·œëª¨ ì‹¤í—˜ |
| A100 80GB | $1.99 | $47.76 | ëŒ€ê·œëª¨ ë°°ì¹˜ |
| H100 80GB | $3.49 | $83.76 | ìµœëŒ€ ì†ë„ |

**KitREC ì „ì²´ ì‹¤í—˜ ì˜ˆìƒ ë¹„ìš©:** $30-50 (RTX 4090 ê¸°ì¤€ ì•½ 3ì¼)

---

## 3. Pod ìƒì„±

### 3.1 ê¶Œì¥ ìŠ¤í™

| í•­ëª© | ìµœì†Œ ì‚¬ì–‘ | ê¶Œì¥ ì‚¬ì–‘ | ìµœì  ì‚¬ì–‘ |
|------|----------|----------|----------|
| **GPU** | RTX 4090 (24GB) | A100 40GB | A100 80GB / H100 |
| **vRAM** | 24GB | 40GB | 80GB |
| **RAM** | 32GB | 64GB | 128GB |
| **Storage** | 50GB | 100GB | 200GB |
| **vCPU** | 8 | 16 | 32 |

### 3.2 Pod ìƒì„± ë‹¨ê³„

```
1. RunPod Console â†’ "Pods" â†’ "+ Deploy"

2. GPU Selection:
   - Community Cloud (ì €ë ´) ë˜ëŠ” Secure Cloud (ì•ˆì •)
   - GPU: NVIDIA RTX 4090 ë˜ëŠ” A100

3. Container Configuration:
   - Template: "RunPod PyTorch 2.2.0"
   - ë˜ëŠ” Custom Image: runpod/pytorch:2.2.0-py3.10-cuda12.1.0-devel-ubuntu22.04

4. Volume:
   - Container Disk: 20GB
   - Volume Disk: 100GB (ëª¨ë¸ ìºì‹œìš©)
   - Volume Mount Path: /workspace

5. Environment Variables:
   - HF_TOKEN: (HuggingFace í† í°)
   - HF_HOME: /workspace/.cache/huggingface

6. "Deploy On-Demand Pod" í´ë¦­
```

### 3.3 ê¶Œì¥ Template ì„¤ì •

```yaml
# Pod Configuration
GPU: RTX 4090 ë˜ëŠ” A100
Container Image: runpod/pytorch:2.2.0-py3.10-cuda12.1.0-devel-ubuntu22.04
Volume: 100GB at /workspace
Expose Ports: 8888 (Jupyter), 22 (SSH)

# Environment Variables
HF_TOKEN=hf_your_token_here
HF_HOME=/workspace/.cache/huggingface
TRANSFORMERS_CACHE=/workspace/.cache/huggingface
CUDA_VISIBLE_DEVICES=0
```

---

## 4. í™˜ê²½ ì„¤ì •

### 4.1 Pod ì ‘ì†

```bash
# ë°©ë²• 1: Web Terminal (RunPod Consoleì—ì„œ "Connect" â†’ "Web Terminal")

# ë°©ë²• 2: SSH (ê¶Œì¥)
ssh root@{POD_IP} -p {SSH_PORT} -i ~/.ssh/your_key
```

### 4.2 ìë™ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ (ê¶Œì¥)

```bash
# 1. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /workspace/Experimental_test

# 2. ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x scripts/setup_runpod.sh
./scripts/setup_runpod.sh
```

### 4.3 ìˆ˜ë™ ì„¤ì • (ë¬¸ì œ ë°œìƒ ì‹œ)

```bash
# 1. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
echo $HF_TOKEN
# ë¹„ì–´ìˆìœ¼ë©´ ì„¤ì •
export HF_TOKEN="hf_your_token_here"
export HF_HOME="/workspace/.cache/huggingface"

# 2. pip ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade pip

# 3. PyTorch í™•ì¸ (ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•¨)
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"

# 4. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install transformers==4.57.3 accelerate==1.12.0 peft==0.13.0
pip install bitsandbytes==0.46.1
pip install datasets huggingface-hub
pip install numpy scipy pandas scikit-learn tqdm pyyaml
pip install openai  # GPT-4.1 í‰ê°€ìš©

# 5. vLLM ì„¤ì¹˜ (ê°€ì¥ ì¤‘ìš”!)
pip install vllm>=0.6.0

# 6. ì„¤ì¹˜ í™•ì¸
python -c "import vllm; print(f'vLLM: {vllm.__version__}')"
```

---

## 5. í”„ë¡œì íŠ¸ ì—…ë¡œë“œ

### 5.1 ë°©ë²• 1: Git Clone (ê¶Œì¥)

```bash
cd /workspace

# GitHubì—ì„œ ì§ì ‘ clone (private repoë©´ token í•„ìš”)
git clone https://github.com/your-username/KitREC.git
cd KitREC/Experimental_test
```

### 5.2 ë°©ë²• 2: SCP ì—…ë¡œë“œ

```bash
# ë¡œì»¬ì—ì„œ ì‹¤í–‰
scp -P {SSH_PORT} -r ./Experimental_test root@{POD_IP}:/workspace/
```

### 5.3 ë°©ë²• 3: RunPod File Browser

```
1. RunPod Console â†’ Pod â†’ "Connect" â†’ "File Browser"
2. Navigate to /workspace
3. Upload ZIP file
4. Unzip: unzip Experimental_test.zip
```

### 5.4 ì—…ë¡œë“œ í›„ ê¶Œí•œ ì„¤ì •

```bash
cd /workspace/Experimental_test
chmod +x scripts/*.sh
chmod +x scripts/*.py
```

---

## 6. í™˜ê²½ ê²€ì¦

### 6.1 ì „ì²´ ê²€ì¦

```bash
cd /workspace/Experimental_test
python scripts/verify_environment.py
```

### 6.2 ì˜ˆìƒ ì¶œë ¥

```
============================================================
 KitREC Environment Verification
============================================================

 Core Packages
  âœ… torch: 2.2.0+cu121
  âœ… transformers: 4.57.3
  âœ… accelerate: 1.12.0
  âœ… peft: 0.13.0
  âœ… datasets: 2.21.0
  âœ… numpy: 1.26.4
  âœ… scipy: 1.14.0

 GPU & CUDA Check
  CUDA Available: True
  CUDA Version: 12.1
  GPU Count: 1
  GPU 0: NVIDIA GeForce RTX 4090 (24.0 GB)
  âœ… Successfully allocated 4GB tensor

 vLLM Check
  âœ… vLLM Version: 0.6.3
  âœ… vLLM LLM class accessible

 HuggingFace Check
  âœ… HF_TOKEN set: hf_aBcD...6789
  âœ… huggingface_hub accessible
  âœ… Can access Qwen/Qwen3-14B model info

 Summary
  packages: âœ… PASS
  cuda: âœ… PASS
  vllm: âœ… PASS
  huggingface: âœ… PASS
  project: âœ… PASS

  ğŸ‰ All checks passed! Environment is ready.
```

### 6.3 ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸

```bash
python scripts/verify_env_and_data.py
```

---

## 7. ì‹¤í—˜ ì‹¤í–‰

### 7.1 ì‹¤í–‰ ìˆœì„œ (ê¶Œì¥)

```bash
# Phase 1: ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ (10 ìƒ˜í”Œ)
python scripts/run_kitrec_eval.py \
    --model_name dualft_music_seta \
    --max_samples 10 \
    --output_dir results/test

# Phase 2: ì¤‘ê·œëª¨ í…ŒìŠ¤íŠ¸ (100 ìƒ˜í”Œ)
python scripts/run_kitrec_eval.py \
    --model_name dualft_music_seta \
    --max_samples 100 \
    --output_dir results/test_100

# Phase 3: ì „ì²´ í‰ê°€ (ê¶Œì¥: tmux/screen ì‚¬ìš©)
tmux new -s kitrec
python scripts/run_kitrec_eval.py \
    --model_name dualft_music_seta \
    --dataset Younggooo/kitrec-test-seta \
    --output_dir results/kitrec \
    --batch_size 8
# Ctrl+B, D ë¡œ detach
```

### 7.2 ì „ì²´ ì‹¤í—˜ ë°°ì¹˜ ì‹¤í–‰

```bash
# 8ê°œ ëª¨ë¸ ìˆœì°¨ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
./scripts/run_all_evaluations.sh
```

### 7.3 Baseline ëª¨ë¸ ì‹¤í–‰

```bash
# CoNet í•™ìŠµ + í‰ê°€
python scripts/run_baseline_eval.py \
    --baseline conet \
    --target_domain movies \
    --candidate_set seta \
    --train_baseline \
    --train_dataset Younggooo/kitrec-dualft_movies-seta

# DTCDR í•™ìŠµ + í‰ê°€
python scripts/run_baseline_eval.py \
    --baseline dtcdr \
    --target_domain movies \
    --candidate_set seta \
    --train_baseline

# LLM4CDR í‰ê°€ (í•™ìŠµ ë¶ˆí•„ìš”)
python scripts/run_baseline_eval.py \
    --baseline llm4cdr \
    --target_domain movies \
    --candidate_set seta
```

---

## 8. ë¬¸ì œ í•´ê²°

### 8.1 CUDA Out of Memory

```bash
# ì¦ìƒ: torch.cuda.OutOfMemoryError

# í•´ê²° 1: batch_size ì¤„ì´ê¸°
--batch_size 4  # ê¸°ë³¸ 8 â†’ 4

# í•´ê²° 2: GPU ë©”ëª¨ë¦¬ ì •ë¦¬
python -c "import torch; torch.cuda.empty_cache()"

# í•´ê²° 3: ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸
nvidia-smi
kill -9 {PID}  # ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
```

### 8.2 vLLM ì„¤ì¹˜ ì‹¤íŒ¨

```bash
# ì¦ìƒ: vLLM import error

# í•´ê²° 1: ì¬ì„¤ì¹˜
pip uninstall vllm -y
pip install vllm --no-cache-dir

# í•´ê²° 2: CUDA ë²„ì „ í™•ì¸
nvcc --version
python -c "import torch; print(torch.version.cuda)"
# ë¶ˆì¼ì¹˜ ì‹œ PyTorch ì¬ì„¤ì¹˜
```

### 8.3 HuggingFace ì¸ì¦ ì˜¤ë¥˜

```bash
# ì¦ìƒ: 401 Unauthorized

# í•´ê²° 1: í† í° í™•ì¸
echo $HF_TOKEN

# í•´ê²° 2: CLI ë¡œê·¸ì¸
pip install huggingface-hub
huggingface-cli login
# í† í° ì…ë ¥

# í•´ê²° 3: í™˜ê²½ ë³€ìˆ˜ ì¬ì„¤ì •
export HF_TOKEN="hf_your_new_token"
```

### 8.4 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ëŠë¦¼

```bash
# í•´ê²°: ìºì‹œ ê²½ë¡œ í™•ì¸ ë° Volume ì‚¬ìš©
export HF_HOME=/workspace/.cache/huggingface
export TRANSFORMERS_CACHE=/workspace/.cache/huggingface

# ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ
python -c "from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('Qwen/Qwen3-14B')"
```

### 8.5 Pod ì—°ê²° ëŠê¹€

```bash
# í•´ê²°: tmux ë˜ëŠ” screen ì‚¬ìš©
tmux new -s experiment
# ì‹¤í—˜ ì‹¤í–‰
# Ctrl+B, D ë¡œ detach

# ì¬ì ‘ì† ì‹œ
tmux attach -t experiment
```

---

## 9. ë¹„ìš© ìµœì í™” íŒ

### 9.1 Spot Instance í™œìš©

```
- Community Cloudì˜ Spot Instance ì‚¬ìš© (ìµœëŒ€ 50% ì €ë ´)
- ë‹¨, ì–¸ì œë“  ì¤‘ë‹¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ checkpoint ì €ì¥ í•„ìˆ˜
```

### 9.2 ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•Œ Pod ì¤‘ì§€

```bash
# RunPod Consoleì—ì„œ "Stop" í´ë¦­
# Volume ë°ì´í„°ëŠ” ìœ ì§€ë¨
# ì¬ì‹œì‘ ì‹œ í™˜ê²½ ì¬ì„¤ì • ë¶ˆí•„ìš”
```

### 9.3 íš¨ìœ¨ì ì¸ ì‹¤í—˜ ìˆœì„œ

```
1. ì‘ì€ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸ (10-100ê°œ) â†’ ì½”ë“œ ê²€ì¦
2. ì¤‘ê°„ ìƒ˜í”Œë¡œ ì„±ëŠ¥ ì¶”ì • (1,000ê°œ) â†’ ì˜ˆìƒ ê²°ê³¼ í™•ì¸
3. ì „ì²´ ì‹¤í—˜ì€ ì•¼ê°„/ì£¼ë§ì— ì‹¤í–‰ â†’ Spot ê°€ê²© ë‚®ìŒ
```

### 9.4 ëª¨ë¸ ìºì‹œ í™œìš©

```bash
# ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì‹œê°„ ì†Œìš”)
# ì´í›„ ìºì‹œì—ì„œ ë¡œë“œ (ë¹ ë¦„)
# Volumeì— ìºì‹œ ì €ì¥í•˜ë©´ Pod ì¬ì‹œì‘ í›„ì—ë„ ìœ ì§€
```

---

## 10. ì²´í¬ë¦¬ìŠ¤íŠ¸

### 10.1 RunPod ë°°í¬ ì „ (ë¡œì»¬)

- [ ] HuggingFace Token ë°œê¸‰ ì™„ë£Œ
- [ ] ë¡œì»¬ ì½”ë“œ ê²€ì¦ í†µê³¼ (`python scripts/verify_local.py`)
- [ ] RunPod ê³„ì • ìƒì„± ë° ê²°ì œ ì„¤ì •
- [ ] í”„ë¡œì íŠ¸ ì½”ë“œ ìµœì‹  ìƒíƒœ í™•ì¸

### 10.2 Pod ìƒì„± í›„

- [ ] SSH ë˜ëŠ” Web Terminal ì ‘ì† í™•ì¸
- [ ] í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (HF_TOKEN)
- [ ] íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ
- [ ] `verify_environment.py` í†µê³¼
- [ ] ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ í†µê³¼

### 10.3 ì‹¤í—˜ ì‹¤í–‰ ì „

- [ ] ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ (10 ìƒ˜í”Œ) ì„±ê³µ
- [ ] tmux/screen ì„¸ì…˜ ìƒì„±
- [ ] ê²°ê³¼ ì €ì¥ ê²½ë¡œ í™•ì¸

---

## ë¶€ë¡: ìœ ìš©í•œ ëª…ë ¹ì–´

```bash
# GPU ìƒíƒœ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
df -h

# í”„ë¡œì„¸ìŠ¤ í™•ì¸
htop

# ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f results/experiment.log

# tmux ì„¸ì…˜ ê´€ë¦¬
tmux ls                    # ì„¸ì…˜ ëª©ë¡
tmux attach -t kitrec      # ì„¸ì…˜ ì—°ê²°
tmux kill-session -t name  # ì„¸ì…˜ ì¢…ë£Œ
```

---

**ì‘ì„± ì™„ë£Œ: 2025-12-07**
