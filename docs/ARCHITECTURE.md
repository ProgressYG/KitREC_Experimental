# KitREC ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:** 2025-12-07  
**ë²„ì „:** 1.0

---

## 1. ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "ğŸ“Š Data Layer"
        HF[("HuggingFace Hub<br/>Datasets")]
        HF --> TRAIN["Training Data<br/>kitrec-dualft_*<br/>kitrec-singleft_*"]
        HF --> VAL["Validation Data<br/>kitrec-val-*"]
        HF --> TEST["Test Data<br/>kitrec-test-*<br/>30,000 samples/set"]
    end

    subgraph "ğŸ¤– Model Layer"
        BASE["Qwen3-14B<br/>(Base Model)"]
        BASE --> DUALFT["DualFT Models<br/>Movies/Music<br/>12K samples"]
        BASE --> SINGLEFT["SingleFT Models<br/>Movies/Music<br/>3K samples"]
        
        DUALFT --> FULL["KitREC-Full<br/>(Thinking)"]
        DUALFT --> DIRECT["KitREC-Direct<br/>(No Thinking)"]
        
        BASE --> COT["Base-CoT<br/>(Zero-shot Thinking)"]
        BASE --> BDIRECT["Base-Direct<br/>(Vanilla Zero-shot)"]
    end

    subgraph "âš™ï¸ Inference Layer"
        VLLM["vLLM Engine<br/>Nvidia 5090 36GB"]
        PARSER["Output Parser<br/>JSON + Think Block"]
        VLLM --> PARSER
    end

    subgraph "ğŸ“ˆ Evaluation Layer"
        RANK["Ranking Metrics<br/>Hit@K, MRR, NDCG"]
        EXPLAIN["Explainability<br/>MAE, RMSE, PPL"]
        STATS["Statistical Analysis<br/>t-test, Holm"]
        GPT["GPT-4.1 Eval<br/>Rationale Quality"]
    end

    subgraph "ğŸ”¬ Baseline Layer"
        CONET["CoNet<br/>(CIKM 2018)"]
        DTCDR["DTCDR<br/>(CIKM 2019)"]
        LLM4CDR["LLM4CDR<br/>(3-Stage Pipeline)"]
    end

    TEST --> VLLM
    FULL --> VLLM
    DIRECT --> VLLM
    COT --> VLLM
    BDIRECT --> VLLM
    
    PARSER --> RANK
    PARSER --> EXPLAIN
    RANK --> STATS
    EXPLAIN --> GPT

    TRAIN --> CONET
    TRAIN --> DTCDR
    TEST --> LLM4CDR
    
    style HF fill:#e1f5fe
    style VLLM fill:#fff3e0
    style RANK fill:#e8f5e9
    style GPT fill:#fce4ec
```

---

## 2. í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡°

```mermaid
graph LR
    subgraph "Experimental_test/"
        ROOT["/"]
        
        ROOT --> SRC["src/"]
        SRC --> DATA["data/<br/>â€¢ data_loader.py<br/>â€¢ prompt_builder.py<br/>â€¢ candidate_handler.py"]
        SRC --> INF["inference/<br/>â€¢ vllm_inference.py<br/>â€¢ output_parser.py<br/>â€¢ batch_inference.py"]
        SRC --> MET["metrics/<br/>â€¢ ranking_metrics.py<br/>â€¢ explainability_metrics.py<br/>â€¢ statistical_analysis.py<br/>â€¢ stratified_analysis.py"]
        SRC --> MOD["models/<br/>â€¢ kitrec_model.py<br/>â€¢ base_model.py"]
        SRC --> UTL["utils/<br/>â€¢ logger.py<br/>â€¢ io_utils.py<br/>â€¢ visualization.py"]
        
        ROOT --> BASE["baselines/"]
        BASE --> BEVAL["base_evaluator.py"]
        BASE --> CONET2["conet/<br/>model, trainer, evaluator"]
        BASE --> DTCDR2["dtcdr/<br/>model, trainer, evaluator"]
        BASE --> LLM["llm4cdr/<br/>prompts, evaluator"]
        
        ROOT --> SCRIPTS["scripts/<br/>â€¢ run_kitrec_eval.py<br/>â€¢ run_ablation_study.py<br/>â€¢ run_baseline_eval.py"]
        ROOT --> RESULTS["results/<br/>kitrec/, ablation/, baselines/"]
        ROOT --> CONFIGS["configs/<br/>*.yaml"]
    end

    style ROOT fill:#fff9c4
    style SRC fill:#e3f2fd
    style BASE fill:#f3e5f5
    style SCRIPTS fill:#e8f5e9
```

---

## 3. ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸

```mermaid
flowchart TB
    subgraph "Phase 1: Base Model"
        QWEN["Qwen/Qwen3-14B"]
    end

    subgraph "Phase 2: PEFT QLoRA Training"
        QWEN --> |"12K samples<br/>3 epochs"| DUALM["DualFT-Movies"]
        QWEN --> |"12K samples<br/>3 epochs"| DUALS["DualFT-Music"]
        QWEN --> |"3K samples<br/>6 epochs"| SINGM["SingleFT-Movies"]
        QWEN --> |"3K samples<br/>6 epochs"| SINGS["SingleFT-Music"]
    end

    subgraph "Phase 3: Ablation Models"
        DUALM --> FULL_M["KitREC-Full-Movies"]
        DUALS --> FULL_S["KitREC-Full-Music"]
        
        QWEN --> |"No Training"| BASE_COT["Base-CoT"]
        QWEN --> |"No Training"| BASE_DIR["Base-Direct"]
        
        DUALM --> |"í•™ìŠµ ë°ì´í„°ì—ì„œ<br/>think ì œê±°"| DIRECT_M["KitREC-Direct-Movies"]
        DUALS --> |"í•™ìŠµ ë°ì´í„°ì—ì„œ<br/>think ì œê±°"| DIRECT_S["KitREC-Direct-Music"]
    end

    subgraph "LoRA Config"
        DUAL_CFG["DualFT Config<br/>r=32, alpha=64<br/>dropout=0.08<br/>LR=2e-4"]
        SING_CFG["SingleFT Config<br/>r=24, alpha=48<br/>dropout=0.15<br/>LR=6e-5"]
    end

    DUAL_CFG -.-> DUALM
    DUAL_CFG -.-> DUALS
    SING_CFG -.-> SINGM
    SING_CFG -.-> SINGS

    style QWEN fill:#bbdefb
    style DUALM fill:#c8e6c9
    style DUALS fill:#c8e6c9
    style SINGM fill:#fff9c4
    style SINGS fill:#fff9c4
```

---

## 4. ì¶”ë¡  ë° í‰ê°€ íŒŒì´í”„ë¼ì¸

```mermaid
sequenceDiagram
    participant HF as HuggingFace Hub
    participant DL as DataLoader
    participant PB as PromptBuilder
    participant VLLM as vLLM Engine
    participant OP as OutputParser
    participant RM as RankingMetrics
    participant EM as ExplainabilityMetrics
    participant SA as StatisticalAnalysis

    HF->>DL: load_test_data()
    DL->>DL: extract_prompt(sample)
    Note over DL: input > instruction<br/>Template Schema ì ìš©

    DL->>PB: build_thinking_prompt() / build_direct_prompt()
    PB->>VLLM: generate(prompt)
    
    VLLM->>OP: parse(raw_output, candidate_ids)
    Note over OP: 1. <think> ë¸”ë¡ ë¶„ë¦¬<br/>2. JSON ì¶”ì¶œ<br/>3. trailing comma ì œê±°<br/>4. item_id ê²€ì¦

    OP->>RM: calculate_all(predictions, gt_id)
    Note over RM: Hit@1, Hit@5, Hit@10<br/>MRR, NDCG@5, NDCG@10

    OP->>EM: mae(), rmse(), perplexity()
    Note over EM: Confidence Score Ã· 2<br/>ì •ê·œí™” ì ìš©

    RM->>SA: paired_t_test(kitrec, baseline)
    SA->>SA: apply_multiple_correction(p_values)
    Note over SA: Holm-Bonferroni<br/>Step-up enforcement
```

---

## 5. Baseline ë¹„êµ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "ê³µí†µ í‰ê°€ ì¸í”„ë¼"
        BEVAL["BaseEvaluator<br/>â€¢ validate_candidate_set()<br/>â€¢ normalize_confidence()<br/>â€¢ calculate_metrics()"]
    end

    subgraph "Deep Learning CDR"
        CONET["CoNet (CIKM 2018)<br/>â€¢ Cross-Network Transfer<br/>â€¢ ID Sequence Input"]
        DTCDR["DTCDR (CIKM 2019)<br/>â€¢ Dual Transfer Learning<br/>â€¢ MLP Mapping"]
    end

    subgraph "LLM-based CDR"
        LLM4CDR["LLM4CDR (2025)<br/>â€¢ 3-Stage Pipeline<br/>â€¢ Domain Gap Analysis<br/>â€¢ User Interest Reasoning<br/>â€¢ Candidate Reranking"]
        VANILLA["Vanilla Zero-shot<br/>â€¢ Base Model Direct<br/>â€¢ Lower Bound"]
    end

    subgraph "KitREC (ì œì•ˆ ëª¨ë¸)"
        KITREC["KitREC-Full<br/>â€¢ Cross-Domain Thinking<br/>â€¢ Knowledge Transfer<br/>â€¢ Confidence + Rationale"]
    end

    BEVAL --> CONET
    BEVAL --> DTCDR
    BEVAL --> LLM4CDR
    BEVAL --> VANILLA
    BEVAL --> KITREC

    subgraph "Candidate Set (ë™ì¼ ì¡°ê±´)"
        CAND["100 candidates<br/>1 GT + 99 Negatives"]
    end

    CAND --> CONET
    CAND --> DTCDR
    CAND --> LLM4CDR
    CAND --> VANILLA
    CAND --> KITREC

    style KITREC fill:#c8e6c9,stroke:#2e7d32,stroke-width:3px
    style BEVAL fill:#e1f5fe
    style CAND fill:#fff3e0
```

---

## 6. User Type ë° Core Level ë§¤í•‘

```mermaid
graph LR
    subgraph "User Distribution (30,000 total)"
        MOVIES["Target: Movies<br/>15,000 users"]
        MUSIC["Target: Music<br/>15,000 users"]
    end

    subgraph "Movies User Types"
        OVL_M["overlapping_books_movies<br/>3,000 (5+ core)"]
        CS2_M["cold_start_2core_movies<br/>3,000"]
        CS3_M["cold_start_3core_movies<br/>3,000"]
        CS4_M["cold_start_4core_movies<br/>3,000"]
        SO_M["source_only_movies<br/>3,000 (1-core)"]
    end

    subgraph "Music User Types"
        OVL_S["overlapping_books_music<br/>3,000 (5+ core)"]
        CS2_S["cold_start_2core_music<br/>3,000"]
        CS3_S["cold_start_3core_music<br/>3,000"]
        CS4_S["cold_start_4core_music<br/>3,000"]
        SO_S["source_only_music<br/>3,000 (1-core)"]
    end

    subgraph "Training Models"
        DUALFT_M["DualFT-Movies<br/>12,000 samples"]
        SINGLEFT_M["SingleFT-Movies<br/>3,000 samples"]
        DUALFT_S["DualFT-Music<br/>12,000 samples"]
        SINGLEFT_S["SingleFT-Music<br/>3,000 samples"]
    end

    OVL_M --> DUALFT_M
    CS2_M --> DUALFT_M
    CS3_M --> DUALFT_M
    CS4_M --> DUALFT_M
    SO_M --> SINGLEFT_M

    OVL_S --> DUALFT_S
    CS2_S --> DUALFT_S
    CS3_S --> DUALFT_S
    CS4_S --> DUALFT_S
    SO_S --> SINGLEFT_S

    style SO_M fill:#ffcdd2
    style SO_S fill:#ffcdd2
    style OVL_M fill:#c8e6c9
    style OVL_S fill:#c8e6c9
```

---

## 7. í‰ê°€ ì§€í‘œ ì²´ê³„

```mermaid
graph TB
    subgraph "Ranking Metrics (ëª¨ë“  ëª¨ë¸)"
        HIT1["Hit@1<br/>ì •í™•íˆ 1ìœ„ ì˜ˆì¸¡"]
        HIT5["Hit@5<br/>Top-5 í¬í•¨"]
        HIT10["Hit@10<br/>Top-10 í¬í•¨"]
        MRR["MRR<br/>1/rank í‰ê· "]
        NDCG5["NDCG@5<br/>Top-5 ë­í‚¹ í’ˆì§ˆ"]
        NDCG10["NDCG@10<br/>Top-10 ë­í‚¹ í’ˆì§ˆ<br/>(ë…¼ë¬¸ í‘œì¤€)"]
    end

    subgraph "Explainability Metrics (KitRECë§Œ)"
        MAE["MAE<br/>|confidence/2 - rating|"]
        RMSE["RMSE<br/>âˆš(confidence/2 - rating)Â²"]
        PPL["Perplexity<br/>rationale í’ˆì§ˆ"]
        GPT["GPT-4.1 Score<br/>â€¢ Logic<br/>â€¢ Specificity<br/>â€¢ Cross-domain<br/>â€¢ Preference"]
    end

    subgraph "Statistical Testing"
        TTEST["Paired t-test<br/>per-sample ë¹„êµ"]
        HOLM["Holm Correction<br/>ë‹¤ì¤‘ ë¹„êµ ë³´ì •"]
        COHEN["Cohen's d<br/>Effect Size"]
    end

    HIT10 --> TTEST
    NDCG10 --> TTEST
    MRR --> TTEST
    TTEST --> HOLM
    TTEST --> COHEN

    style NDCG10 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px
    style GPT fill:#fce4ec
    style HOLM fill:#e1f5fe
```

---

## 8. Research Questions ì‹¤í—˜ ë§¤í•‘

```mermaid
graph TB
    subgraph "RQ1: Ablation Study (2Ã—2)"
        RQ1["KitREC êµ¬ì¡° íš¨ê³¼ ê²€ì¦"]
        RQ1 --> FULL["â‘  KitREC-Full<br/>(Fine-tuned + Thinking)"]
        RQ1 --> DIRECT["â‘¡ KitREC-Direct<br/>(Fine-tuned + No Thinking)"]
        RQ1 --> COT["â‘¢ Base-CoT<br/>(Untuned + Thinking)"]
        RQ1 --> BDIR["â‘£ Base-Direct<br/>(Untuned + No Thinking)"]
    end

    subgraph "RQ2: CDR ë¹„êµ"
        RQ2["CDR ë°©ì‹ íš¨ê³¼ ê²€ì¦"]
        RQ2 --> VS_CONET["vs CoNet"]
        RQ2 --> VS_DTCDR["vs DTCDR"]
        RQ2 --> VS_LLM4["vs LLM4CDR"]
        RQ2 --> VS_VAN["vs Vanilla"]
    end

    subgraph "RQ3: Cold-start"
        RQ3["Cold-start í•´ê²° ê²€ì¦"]
        RQ3 --> C1["1-core<br/>(ê·¹í•œ Cold-start)"]
        RQ3 --> C2["2-core"]
        RQ3 --> C3["3-core"]
        RQ3 --> C4["4-core"]
        RQ3 --> C5["5+-core<br/>(Warm-start)"]
    end

    subgraph "RQ4: Explainability"
        RQ4["ì„¤ëª…ë ¥ ê²€ì¦<br/>(KitRECë§Œ)"]
        RQ4 --> CONF["Confidence Score<br/>MAE, RMSE"]
        RQ4 --> RAT["Rationale Quality<br/>PPL, GPT-4.1"]
    end

    style RQ1 fill:#e3f2fd
    style RQ2 fill:#f3e5f5
    style RQ3 fill:#fff3e0
    style RQ4 fill:#fce4ec
```

---

## 9. ë°ì´í„° íë¦„ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
flowchart LR
    subgraph "Input"
        HF["HuggingFace Hub"]
        HF --> |"Training"| TRAIN["kitrec-dualft_*<br/>kitrec-singleft_*"]
        HF --> |"Test"| TEST["kitrec-test-seta<br/>kitrec-test-setb"]
    end

    subgraph "Processing"
        TRAIN --> |"90:10 split"| TRVAL["Train/Val<br/>Stratified by user_type"]
        TEST --> |"extract_prompt()"| PROMPT["Prompt<br/>(input field)"]
        TEST --> |"extract_ground_truth()"| GT["Ground Truth<br/>{item_id, title, rating}"]
        TEST --> |"extract_candidate_ids()"| CAND["Candidate IDs<br/>100 items"]
    end

    subgraph "Inference"
        PROMPT --> VLLM["vLLM Engine"]
        VLLM --> RAW["Raw Output<br/><think>...JSON"]
        RAW --> PARSE["Parsed Result<br/>â€¢ thinking<br/>â€¢ predictions[]<br/>â€¢ errors[]"]
    end

    subgraph "Validation"
        PARSE --> VALID{"item_id in<br/>candidates?"}
        VALID --> |"Yes"| METRICS["Metrics Calculation"]
        VALID --> |"No"| FAIL["rank = âˆ<br/>(fail)"]
    end

    subgraph "Output"
        METRICS --> RESULTS["results/<br/>â€¢ predictions.jsonl<br/>â€¢ metrics_summary.json<br/>â€¢ error_statistics.json"]
        FAIL --> STATS["Error Statistics<br/>â€¢ parse_failure_rate<br/>â€¢ invalid_item_rate"]
    end

    style HF fill:#e1f5fe
    style VLLM fill:#fff3e0
    style VALID fill:#ffecb3
    style RESULTS fill:#c8e6c9
```

---

## 10. í™˜ê²½ êµ¬ì„±

```mermaid
graph TB
    subgraph "Hardware"
        GPU["Nvidia 5090<br/>36GB VRAM"]
        CPU["Host System"]
    end

    subgraph "Software Stack"
        VENV["Python venv"]
        VENV --> TORCH["PyTorch 2.2+"]
        VENV --> TRANS["Transformers 4.57.3"]
        VENV --> PEFT["PEFT 0.13.0"]
        VENV --> VLLM["vLLM"]
        VENV --> BNB["bitsandbytes"]
    end

    subgraph "External Services"
        HF["HuggingFace Hub<br/>â€¢ Datasets<br/>â€¢ Models"]
        OPENAI["OpenAI API<br/>GPT-4.1 (RQ4)"]
    end

    subgraph "Environment Variables"
        ENV["HF_TOKEN<br/>OPENAI_API_KEY"]
    end

    GPU --> VLLM
    TORCH --> TRANS
    ENV --> HF
    ENV --> OPENAI

    style GPU fill:#ffecb3
    style VLLM fill:#e1f5fe
    style HF fill:#f3e5f5
```

---

## ì°¸ì¡° ë¬¸ì„œ

| ë¬¸ì„œ | ì„¤ëª… |
|------|------|
| `CLAUDE.md` | í”„ë¡œì íŠ¸ ìƒì„¸ ê°€ì´ë“œ |
| `detail_task_plan.md` | ì‘ì—… ê³„íšì„œ |
| `IMPLEMENTATION_SUMMARY.md` | êµ¬í˜„ ìš”ì•½ |
| `DATA_FLOW.md` | ë°ì´í„° íë¦„ ìƒì„¸ |
| `RQ_EXPERIMENT_MAP.md` | RQë³„ ì‹¤í—˜ ë§¤í•‘ |

