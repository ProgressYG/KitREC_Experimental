#!/usr/bin/env python3
"""
KitREC í™˜ê²½ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

RunPod í™˜ê²½ ì„¤ì • í›„ ì‹¤í–‰í•˜ì—¬ ëª¨ë“  ì˜ì¡´ì„±ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
"""

import sys
import os

def print_header(title):
    print(f"\n{'='*60}")
    print(f" {title}")
    print(f"{'='*60}")

def check_import(module_name, min_version=None):
    """ëª¨ë“ˆ import ë° ë²„ì „ í™•ì¸"""
    try:
        module = __import__(module_name)
        version = getattr(module, "__version__", "unknown")
        status = "âœ…"

        if min_version and version != "unknown":
            from packaging import version as pkg_version
            if pkg_version.parse(version) < pkg_version.parse(min_version):
                status = "âš ï¸ "

        print(f"  {status} {module_name}: {version}")
        return True
    except ImportError as e:
        print(f"  âŒ {module_name}: NOT INSTALLED ({e})")
        return False

def check_cuda():
    """CUDA ë° GPU í™•ì¸"""
    print_header("GPU & CUDA Check")

    try:
        import torch

        cuda_available = torch.cuda.is_available()
        print(f"  CUDA Available: {cuda_available}")

        if cuda_available:
            print(f"  CUDA Version: {torch.version.cuda}")
            print(f"  cuDNN Version: {torch.backends.cudnn.version()}")

            gpu_count = torch.cuda.device_count()
            print(f"  GPU Count: {gpu_count}")

            for i in range(gpu_count):
                props = torch.cuda.get_device_properties(i)
                memory_gb = props.total_memory / (1024**3)
                print(f"  GPU {i}: {props.name} ({memory_gb:.1f} GB)")

            # Memory test
            print(f"\n  Memory Test:")
            try:
                x = torch.zeros(1024, 1024, 1024, device='cuda')  # ~4GB
                del x
                torch.cuda.empty_cache()
                print(f"    âœ… Successfully allocated 4GB tensor")
            except Exception as e:
                print(f"    âš ï¸  Memory test failed: {e}")

            return True
        else:
            print("  âŒ CUDA not available!")
            return False

    except Exception as e:
        print(f"  âŒ Error: {e}")
        return False

def check_vllm():
    """vLLM ì„¤ì¹˜ í™•ì¸"""
    print_header("vLLM Check")

    try:
        import vllm
        print(f"  âœ… vLLM Version: {vllm.__version__}")

        # Check if vLLM can see GPU
        from vllm import LLM
        print(f"  âœ… vLLM LLM class accessible")

        return True
    except ImportError as e:
        print(f"  âŒ vLLM not installed: {e}")
        return False
    except Exception as e:
        print(f"  âš ï¸  vLLM installed but error: {e}")
        return True

def check_huggingface():
    """HuggingFace í† í° ë° ì ‘ê·¼ í™•ì¸"""
    print_header("HuggingFace Check")

    # Check token
    hf_token = os.environ.get("HF_TOKEN")
    if hf_token:
        masked = hf_token[:8] + "..." + hf_token[-4:]
        print(f"  âœ… HF_TOKEN set: {masked}")
    else:
        print(f"  âš ï¸  HF_TOKEN not set (needed for private models)")

    # Check huggingface_hub
    try:
        from huggingface_hub import HfApi
        api = HfApi()
        print(f"  âœ… huggingface_hub accessible")

        # Try to access a public model
        try:
            api.model_info("Qwen/Qwen3-14B")
            print(f"  âœ… Can access Qwen/Qwen3-14B model info")
        except Exception as e:
            print(f"  âš ï¸  Cannot access model info: {e}")

        return True
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return False

def check_project_structure():
    """í”„ë¡œì íŠ¸ êµ¬ì¡° í™•ì¸"""
    print_header("Project Structure Check")

    required_dirs = [
        "configs",
        "src/data",
        "src/models",
        "src/inference",
        "src/metrics",
        "src/utils",
        "baselines/conet",
        "baselines/dtcdr",
        "baselines/llm4cdr",
        "scripts",
        "results",
    ]

    required_files = [
        "configs/eval_config.yaml",
        "configs/model_paths.yaml",
        "src/data/data_loader.py",
        "src/inference/vllm_inference.py",
        "src/metrics/ranking_metrics.py",
        "scripts/run_kitrec_eval.py",
    ]

    # Get project root
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)

    print(f"  Project root: {project_root}")

    all_ok = True

    # Check directories
    for dir_path in required_dirs:
        full_path = os.path.join(project_root, dir_path)
        if os.path.isdir(full_path):
            print(f"  âœ… {dir_path}/")
        else:
            print(f"  âŒ {dir_path}/ NOT FOUND")
            all_ok = False

    # Check key files
    print()
    for file_path in required_files:
        full_path = os.path.join(project_root, file_path)
        if os.path.isfile(full_path):
            print(f"  âœ… {file_path}")
        else:
            print(f"  âŒ {file_path} NOT FOUND")
            all_ok = False

    return all_ok

def run_quick_inference_test():
    """ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ (ì„ íƒì )"""
    print_header("Quick Inference Test (Optional)")

    response = input("  Run quick inference test? (y/N): ").strip().lower()
    if response != 'y':
        print("  Skipped.")
        return True

    try:
        print("  Loading tokenizer...")
        from transformers import AutoTokenizer
        tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen3-14B", trust_remote_code=True)
        print("  âœ… Tokenizer loaded successfully")

        # Simple tokenization test
        test_text = "This is a test recommendation prompt."
        tokens = tokenizer.encode(test_text)
        print(f"  âœ… Tokenization works: {len(tokens)} tokens")

        return True
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return False

def main():
    print("\n" + "="*60)
    print(" KitREC Environment Verification")
    print("="*60)

    results = {}

    # 1. Core packages
    print_header("Core Packages")
    packages = [
        ("torch", "2.2.0"),
        ("transformers", "4.50.0"),
        ("accelerate", "1.0.0"),
        ("peft", "0.10.0"),
        ("datasets", "2.16.0"),
        ("numpy", None),
        ("scipy", None),
        ("pandas", None),
        ("tqdm", None),
        ("yaml", None),
    ]

    pkg_ok = all(check_import(pkg, ver) for pkg, ver in packages)
    results["packages"] = pkg_ok

    # 2. CUDA
    results["cuda"] = check_cuda()

    # 3. vLLM
    results["vllm"] = check_vllm()

    # 4. HuggingFace
    results["huggingface"] = check_huggingface()

    # 5. Project structure
    results["project"] = check_project_structure()

    # Summary
    print_header("Summary")

    all_ok = all(results.values())

    for check, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"  {check}: {status}")

    print()
    if all_ok:
        print("  ğŸ‰ All checks passed! Environment is ready.")
        print()
        print("  Next steps:")
        print("  1. python scripts/run_kitrec_eval.py --help")
        print("  2. python scripts/run_kitrec_eval.py --model_name dualft_music_seta --max_samples 10")
    else:
        print("  âš ï¸  Some checks failed. Please fix the issues above.")
        sys.exit(1)

if __name__ == "__main__":
    main()
